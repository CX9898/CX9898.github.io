<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>CX98的博客</title><link>https://CX9898.github.io</link><description>HPC练习生</description><copyright>CX98的博客</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://cx9898.github.io/img/CX.jpg</url><title>avatar</title><link>https://CX9898.github.io</link></image><lastBuildDate>Thu, 09 Jan 2025 07:45:58 +0000</lastBuildDate><managingEditor>CX98的博客</managingEditor><ttl>60</ttl><webMaster>CX98的博客</webMaster><item><title>如何阅读论文</title><link>https://CX9898.github.io/post/ru-he-yue-du-lun-wen.html</link><description>![封面](/img/[论文笔记]如何阅读论文/封面.png)&#13;
&#13;
# [论文笔记]如何阅读论文&#13;
&#13;
**How to Read a Paper**&#13;
&#13;
论文于2007年发表在ACM SIGCOMM Computer Communication ReviewVolume 37Issue. 研究人员花费大量时间阅读论文, 学习有效地阅读论文是一项很关键但很少教的技能. 这篇论文概述了阅读研究论文的'三遍(THREE-PASS)'法. 描述了如何使用这种方法做文献调查.&#13;
&#13;
文章链接: [[论文笔记]如何阅读论文](https://zhuanlan.zhihu.com/p/704095836)&#13;
&#13;
---&#13;
&#13;
## 三遍(THREE-PASS)法&#13;
&#13;
核心思想是, 应该最多阅读一篇论文三次, 而不是从头开始一路看到最后. 在每一遍阅读中, 都要完成特定的目标. 第一遍对论文有一个大致的了解, 第二遍掌握论文的大致内容, 第三遍深入理解论文.&#13;
&#13;
---&#13;
&#13;
### 第一遍&#13;
&#13;
快速浏览整个论文. 大约花费5到10分钟:&#13;
&#13;
1. **仔细阅读标题, 摘要和介绍**&#13;
2. **阅读章节和子章节标题**&#13;
3. **阅读结论**&#13;
4. **浏览参考文献, 在脑海中勾出已经读过的论文**&#13;
&#13;
在'第一遍'结束时, 应该能回答出五个问题:&#13;
&#13;
1. **分类: 这是什么类型的论文?**&#13;
2. **背景: 与哪些论文有关? 用了哪些理论基础来分析问题?**&#13;
3. **正确性: 论文的假设是否合理?**&#13;
4. **贡献: 论文的主要贡献是什么?**&#13;
5. **清晰性: 论文写的好不好?**&#13;
&#13;
根据以上信息, 可以选择要不要继续阅读这篇论文. 可能是因为对这篇论文不感兴趣, 或者对这个领域不够了解, 无法理解这篇论文,&#13;
或者作者做出了无效的假设.&#13;
&#13;
&gt; 在这里, 作者还提到了, 当写一篇论文时, 可以参考大多数审稿人和读者只会通过这一遍的阅读. 如果审稿人阅读完一篇还不能理解主旨, 论文很可能会被拒绝. 如果读者在5分钟还不能理解论文的亮点, 那么论文很可能不会被阅读. 撰写论文时主要要选择连贯的章节和子章节标题, 并要写出简明而且全面的摘要.&#13;
&#13;
---&#13;
&#13;
### 第二遍&#13;
&#13;
第二遍要更仔细地阅读论文, 但忽略细节. 在阅读过程中, 记下要点或在空白处做出点评会很有帮助.&#13;
&#13;
1. **仔细看论文中的图形, 图表和其他插图. 特别注意图表. 坐标轴的标注是否正确. 结果是否显示了误差条.&#13;
   像这样的常见错误会把仓促、粗制滥造的作品和真正优秀的作品区分开.**&#13;
2. **标记相关的未读参考文献(这是了解更多论文背景的好方法). 这些文献可能会对你的研究有帮助.**&#13;
&#13;
第二遍最多花费1个小时. 过了第一遍, 应该能够掌握论文的内容, 并且能够总结论文的主要内容. 阅读到这种程度适用于这是一篇感兴趣的论文, 但是不在你的研究方向上.&#13;
&#13;
有时候甚至在第二遍结束的时候也看不懂一篇论文. 很可能是因为主题对你来说是新的, 有不熟悉的术语和缩略词,&#13;
或者作者使用了你不理解的证明和实验技术. 当然也可能是论文写的不好, 有很多未经证实的断言和大量的引用. 也有可能只是因为累了. 到这里可以选择:&#13;
&#13;
1. 论文放在一边, 寄希望于不需要理解这篇论文就能在事业上取得成功.&#13;
2. 稍后再回到论文.&#13;
3. 坚持继续阅读第三遍.&#13;
&#13;
---&#13;
&#13;
### 第三遍&#13;
&#13;
要完全理解一篇论文, 特别是对于复读者, 需要进行第三遍阅读. **第三遍的关键在于尝试在脑海中重现论文: 做出和作者相同的假设, 重新创作作品. 通过将这种再创作与实际论文进行比较, 不仅可以轻松识别一篇论文的创新之处, 还可以识别论文的缺陷和假设.**&#13;
&#13;
这一遍需要非常注意细节. 应该识别并挑战每一个假设. 并且应该考虑如果是自己的话将如何表达一个特定的想法.&#13;
这种实际与虚拟的比较有助于深入了解论文中的证明和展示方法, 很可能会将其添加到你的工具库中. 在这个过程中, 还应该记下未来工作的想法.&#13;
&#13;
对于初学者来说, 这一遍需要4到5个小时, 对于有经验的读者大概需要一个小时. 在第三遍阅读完, 应该能根据记忆重构论文的整个结构, 能够识别它的优缺点. 特别是, 应该能准确地指出论文的强项和弱项, 包括隐含的假设、遗漏的引用以及实验或分析技术中可能存在的问题等.&#13;
&#13;
---&#13;
&#13;
## 如何做一个文献调查&#13;
&#13;
在做文献调查时, 论文阅读技巧的重要性更加明显. 需要在可能是一个不熟悉的领域中阅读数十篇论文. 在一个不熟悉的领域应该细读阅读哪些论文?&#13;
&#13;
### 选择论文&#13;
&#13;
首先, **使用谷歌Scholar或CiteSeer等学术搜索引擎, 选择一些精心挑选的关键词. 找到该领域最近的三到五篇论文. 对每篇论文进行' 第一遍'阅读, 获得对该工作的初步了解, 然后仔细阅读这些论文的'相关工作'部分.** 这里通常会包含对近期这一领域的研究的简要总结. 如果幸运的话还能找到一篇最新的综述论文. 只要阅读这篇综述论文工作就完成了, 然后恭喜自己好运.&#13;
&#13;
### 确定关键论文和研究人员&#13;
&#13;
如果在'第一遍'阅读没有找到综述论文, 那么下一步是在这些论文的参考文献中寻找共享的引用和重复出现的作者名字.&#13;
这些共享引用和重复出现的作者通常代表该领域的关键论文和重要研究人员. 将这些关键论文下载下来, 放在一边备用,&#13;
有可能会成为文献调查的基础和核心.&#13;
&#13;
### 识别顶级会议和期刊&#13;
&#13;
接下来, 访问这些关键研究人员的个人或机构网站, 查看他们最近发表的论文. 通过这种方式, 你可以了解该领域的顶级会议和期刊,&#13;
因为优秀的研究人员通常会在这些顶级会议和期刊上发表他们的研究成果. 然后, 前往这些顶级会议和期刊的官方网站,&#13;
查看它们最近的会议记录或期刊文章. 通过快速浏览, 通常可以识别出近期高质量的相关工作.&#13;
&#13;
这些论文连同之前保留的关键论文一起, 构成了调查的第一个版本. 对这些论文进行两遍阅读. 在阅读过程中, 注意它们是否都引用了之前没有找到的关键论文. 如果是, 那么获取并阅读这篇关键论文, 并根据需要进行迭代.&#13;
&#13;
---&#13;
&#13;
## 总结&#13;
&#13;
论文主要介绍了一种高效阅读研究论文的方法:'三遍(THREE-PASS)'法, 并探讨了如何利用这种方法进行文献调查. 作者在过去15年里, 一直使用这种方法来阅读会议论文集, 撰写评论, 做背景研究等. 证明了'三遍(THREE-PASS)'法的有效性. **这篇论文提供了一种阅读论文的方法, 属于实在阅读论文中学习怎么阅读论文. 这个方法可以帮助研究人员更高效地获取信息, 理解内容并进行学术研究.**&#13;
&#13;
论文链接: [How to Read a Paper](https://dl.acm.org/doi/abs/10.1145/1273445.1273458)。</description><guid isPermaLink="true">https://CX9898.github.io/post/ru-he-yue-du-lun-wen.html</guid><pubDate>Thu, 09 Jan 2025 06:40:35 +0000</pubDate></item><item><title>高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法</title><link>https://CX9898.github.io/post/gao-xiao-de-kuai-xi-shu-gan-zhi-%28BSA%29-ju-zhen-zhong-pai-xu-fang-fa-yi-chong-fen-li-yong-zhang-liang-he-xin-jia-su-xi-shu-ju-zhen---duo-xiang-liang-cheng-fa.html</link><description>![Accelerated Block-Sparsity-Aware Matrix Reordering for Leveraging Tensor Cores in Sparse Matrix-Multivector Multiplication](/img/[论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法/封面.png)&#13;
&#13;
# [论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法&#13;
&#13;
**Accelerated Block-Sparsity-Aware Matrix Reordering for Leveraging Tensor Cores in Sparse Matrix-Multivector&#13;
Multiplication**&#13;
&#13;
论文于2024年发表于Euro-Par 2024会议(30th International European Conference on Parallel and Distributed Computing).&#13;
&#13;
稀疏矩阵-多向量乘法(SpMM)又称为稀疏矩阵-稠密矩阵乘法是深度学习模型和科学计算应用中的关键内核.&#13;
然而, 由于非零元素的不规则分布和其产生的不规则内存访问模式, 实现高性能的SpMM具有挑战性.&#13;
在论文中, 提出了一种新颖的稀疏矩阵重排序算法, 该算法考虑了块稀疏性, 以增强Tensor Cores上SpMM的数据局部性.&#13;
对大量稀疏矩阵的实验结果表明了重排序算法的有效性以及利用Tensor Cores进行SpMM的好处.&#13;
&#13;
文章链接: [[论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法](https://zhuanlan.zhihu.com/p/14997232589)&#13;
&#13;
---&#13;
&#13;
## 引言&#13;
&#13;
几个最先进的深度学习模型, 如卷积神经网络, 图神经网络和TransFormer, 在训练和推理阶段都执行大量的矩阵-矩阵乘法.&#13;
因此, 专门化的加速器, 如TPU(Tensor Processing Unit)和NVIDIA的Tensor Cores, 最近被引入来加速稠密矩阵-稠密矩阵乘法(DMM).&#13;
&#13;
SpMM核心在GPU上存在基本的计算挑战. 首先, 左乘的稀疏矩阵和右乘的稠密矩阵中元素的不规则访问由左乘稀疏矩阵中非零元素的位置决定.&#13;
这种不规则的内存访问导致GPU上全局内存的带宽的低效使用和缓存命中率降低. 其次, 稀疏矩阵中非零元素的不规则分布导致负载不平衡问题和GPU上可利用的并行性的降低.&#13;
&#13;
之前一些优化SpMM的努力主要集中在重新排列稀疏矩阵以提高数据局部性. 稀疏矩阵重新排序的主要目标是重新组织原始矩阵,&#13;
从重新排序矩阵中获得的密集块可以用来与右乘矩阵进行稠密矩阵-稠密矩阵乘法.&#13;
&#13;
论文的主要目标是开发一种新颖的加速块稀疏感知(Block-Sparsity-Aware)重排算法. 用于在GPU上高效的重排不规则稀疏矩阵中的行,&#13;
旨在提取高密度块并明智地利用Tensor Cores进行SpMM.&#13;
&#13;
为了克服基于列索引的聚类问题, 论文的矩阵重排算法首先将行划分为多个列块, 以识别块级稀疏模式, 以识别块稀疏模式.&#13;
为了增强SpMM的数据局部性, 在行聚类过程中, BSA重排算法不仅考虑了非零列块的位置, 还考虑每个列块中非零项的数量.&#13;
为了有效地测量编码行向量之间的相似度, 采用考虑向量实际的加权Jaccard相似度.&#13;
&#13;
&gt; 加权Jaccard相似度:&#13;
&#13;
在对行进行重排序后, 根据密度阈值将重排序后的矩阵拆分为稠密块和稀疏剩余.&#13;
采用Blocked-Ellpack格式来储存稠密块中的元素, 并利用NVIDIA的cuSPARSE Block-SpMM来加速运算稠密矩阵.&#13;
对于稀疏剩余部分, 使用压缩稀疏行(CSR)格式来储存, 并在常规CUDA核心上使用NVIDIA的cuPARSE进行SpMM操作.&#13;
&#13;
&gt; Blocked-Ellpack格式: Blocked-Ellpack格式是ELLPACK格式的一个变种, 将矩阵划分为多个块, 每个块内部使用ELLPACK格式储存.&#13;
&gt; ELLPACK格式是一种储存稀疏矩阵的压缩格式, 它将每一行的非零元素按列索引排序后储存.&#13;
&#13;
使用来自深度学习矩阵集合的2586个稀疏矩阵进行广泛的比较和评估,&#13;
结果表明,论文的并行SpMM实现(称为BSA-SpMM)比最先进的替代方案实现了高达21.99倍的加速.&#13;
&#13;
---&#13;
&#13;
## 背景及相关工作&#13;
&#13;
### 稀疏矩阵-多向量乘法(SpMM)&#13;
&#13;
几个最先进的深度学习模型, 如卷积神经网络, 图神经网络和TransFormer, 在训练和推理阶段都执行大量的稀疏矩阵-矩阵乘法(SpMM).&#13;
SpMM是将M × K的稀疏输入矩阵S与大小为K × N的稠密输入矩阵D相乘, 生成大小为M×N的稠密输出矩阵O. 即O = S × D.&#13;
&#13;
![SpMM](/img/[论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法/SpMM.png)&#13;
SpMM&#13;
&#13;
SpMM在GPU上存在基本的计算挑战. 首先, 左乘的稀疏矩阵和右乘的稠密矩阵中元素的不规则访问由左乘稀疏矩阵中非零元素的位置决定.&#13;
这种不规则的内存访问导致GPU上全局内存的带宽的低效使用和缓存命中率降低. 其次, 稀疏矩阵中非零元素的不规则分布导致负载不平衡问题和GPU上可利用的并行性的降低.&#13;
&#13;
稀疏矩阵可以表示为基于块的稀疏格式, 例如Blocked-Ellpack格式和Variable Block Row(VBR)格式.&#13;
&#13;
Blocked-Ellpack格式的主要优势在于它可以有效利用Tensor Cores.&#13;
特别是使用Blocked-Ellpack格式时, 可以通过使用NVIDIA的cuSPARSE库的 `cusparseSpMM()` 函数来利用Tensor Cores进行并行块矩阵乘法.&#13;
&#13;
VBR格式与Blocked-Ellpack格式不同的是它会储存不同大小的非零块.&#13;
而NVIDIA的cuBLAS库的 `cublasGemmEx()` 函数支持可变的矩阵大小, 可以通过这个函数以利用Tensor Cores进行稀疏矩阵-稠密矩阵乘法.&#13;
&#13;
---&#13;
&#13;
## 带有Tensor Cores的图形处理器(GPU)&#13;
&#13;
Tensor Cores是NVIDIA开发的一种专门用于加速矩阵-矩阵乘法和累加的硬件单元.&#13;
在Volta架构中首次引入, 并在后续的Ampere架构和Hopper架构中得到了进一步的优化.&#13;
&#13;
为了高效执行矩阵-矩阵乘法和累加操作, 通过32个线程一组的线程束(warp)协作并行处理矩阵中的子矩阵块. 与标准单精度(FP32)&#13;
浮点格式相比, Tensor Cores通过利用低精度浮点格式(例如FP16), 实现了更高的性能和更低的内存需求.&#13;
&#13;
&gt; 关于Tensor core的具体内容可参考另一篇文章: [CUDA 编程使用 Tensor core 详解](https://zhuanlan.zhihu.com/p/706494789)&#13;
&#13;
---&#13;
&#13;
## 用Tensor Core实现SpMM的挑战&#13;
&#13;
Tensor Core 是专为高性能矩阵计算设计的硬件加速单元, 特别擅长处理密集矩阵乘法. 然而，SpMM中稀疏矩阵的计算模式难以直接适配&#13;
Tensor Core 的工作方式, 需要优化数据格式和计算流程来高效利用硬件潜力.&#13;
&#13;
Tensor Core用于计算两个矩阵块的乘法和累加, 而直接在Tensor Core上处理SpMM中会因为每个块中计算的有效数据数量较少而导致资源的浪费.&#13;
例如, 下面这个分块矩阵只有两个非零元素, 而Tensor core是一起计算整个矩阵块, 经过Tensor core计算后只有两个数据是有效数据.&#13;
&#13;
![两个非零元素的分块矩阵](/img/[论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法/两个非零元素的矩阵块.png)&#13;
4×4的矩阵块中只有两个非零元素&#13;
&#13;
之前一些优化SpMM的努力主要集中在重新排列稀疏矩阵以提高数据局部性. 稀疏矩阵重新排序的主要目标是重新组织原始矩阵,&#13;
从重新排序矩阵中获得的密集块可以用来与右乘矩阵进行稠密矩阵-稠密矩阵乘法. 核心思想是将原稀疏矩阵的元素打乱顺序,&#13;
将具有同一行但不同列的元素或同一列但不同行的元素集合在一起, 以形成密集块(但也有可能会有零元素).&#13;
&#13;
通过重排序稀疏矩阵的数据, 根据列密度对每个行面板的列或对每个列面板的行进行重排, 形成密集分块. 能够有效的增加资源利用率.&#13;
例如, 输入稀疏矩阵中某一块数据拥有下图这种性质.&#13;
&#13;
![稀疏矩阵聚类的例子](/img/[论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法/稀疏矩阵聚类的例子.png)&#13;
稀疏矩阵聚类的例子&#13;
&#13;
左稀疏块的数据拥有所在同一行或同一列的属性, 可以将其聚类为右边的密集块, 保留其所在原始位置的信息. 通过将类似这样可以聚类的数据聚合成密集块,&#13;
再通过Tensor core进行计算, 能够大大加快运算时间.&#13;
&#13;
**论文的主要目标是开发一种新颖的加速块稀疏感知(Block-Sparsity-Aware)重排算法. 与以上例子不同的是只针对每行进行比较和重组.&#13;
块稀疏感知(Block-Sparsity-Aware)重排算法在GPU上高效的重排不规则稀疏矩阵中的行, 旨在提取高密度块并明智地利用Tensor&#13;
Cores进行SpMM.**&#13;
&#13;
---&#13;
&#13;
## 关于稀疏矩阵重排以优化稀疏矩阵乘法(SpMM)的相关工作&#13;
&#13;
为了增强SpMM的数据局部性, 最近已经开发除了集中稀疏重排序和压缩算法.&#13;
以往基于利用Tensor Cores, 为稀疏矩阵重排序的努力大致可以分为两类.&#13;
&#13;
Hong等人提出了一种自适应稀疏分块(ASpT)方法, 首先将稀疏矩阵划分为多个行面板, 其中每个行面板由连续的行组成.&#13;
然后, 根据列密度对每个行面板的列进行重排, 形成密集分块.&#13;
Jiang等人进一步扩展了ASpT方法, 引入了一种行重排技术, 称为ASpT-RR.&#13;
ASpT-RR不是直接将稀疏矩阵的连续行分为行面板, 而是首先对行进行重排, 将相似的行分组到同一个行面板中.&#13;
但是当非零元素的列索引广泛分散时, 基于非零元素的列索引对行进行重排可能导致聚类失败.&#13;
Gale等人提出了一种行交换技术(称为Sputnik), 根据每行的非零元素数量重新排列行, 以实现GPU上常规SM中的负载均衡.&#13;
&#13;
&gt; 聚类(clustering)是指将具有相似特征的元素放在一起, 以提高缓存利用率和计算效率. 聚类失败意味着由于非零元素的列索引过于分散,&#13;
&gt; 无法通过重排来形成连续的块, 从而无法利用处理器的向量化指令或其他优化手段来提高性能, 可能导致计算效率降低.&#13;
&#13;
Labini等人提出了一种称为1-SA的行重排序技术, 该技术使用一种基于Saad算法的变体, 通过一维分块对行进行重排序.&#13;
1-SA将行划分为多个列分区, 并基于非零列分区模式的Jaccard相似度对行进行聚类.&#13;
使用VBR格式储存包含非零元素的变大小块, 使用NVIDIA的 `cublasGemmEx()` 函数利用Tensor Cores将这些块与右乘稠密矩阵相乘.&#13;
但是1-SA方法重新排序的矩阵中稀疏填充的块即使只包含一个非零元素, 也是以VBR格式储存, 然后传递给Tensor Cores进行计算.&#13;
Tensor Core上处理这些稀疏块会因为每个块中填充的零数量较多而导致利用率不足.&#13;
Yuke等人提出了一种稀疏图转换方案(称为TC-GNN), 将稀疏矩阵的行面板中的非零元素压缩, 以利用Tensor Cores进行SpMM操作.&#13;
但是在对行面板中非零元素进行压缩时, TC-GNN忽略了考虑各列中非零元素数量的变化, 并且没有比较行之间的稀疏模式.&#13;
&#13;
---&#13;
&#13;
## BSA-SpMM: 块稀疏感知矩阵乘法&#13;
&#13;
在本节中, 首先描述BSA-SpMM的概述. 然后讲解在比较行过程中使用的方法, 最后详细介绍块稀疏感知(BSA)重排序算法. 稀疏感知(BSA)&#13;
重排序算法的核心思想是将原稀疏矩阵的每一行都拆分开, 重新排列顺序(记录原行ID), 将相似的行排列在一起, 以形成密集块.&#13;
密集块通过Tensor Core核心计算, 剩余部分利用CUDA核心计算.&#13;
&#13;
---&#13;
&#13;
### BSA-SpMM概述&#13;
&#13;
![BSA-SpMM概述图](/img/[论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法/BSA-SpMM概述图.png)&#13;
BSA-SpMM概述图&#13;
&#13;
BSA-SpMM的总流程如图所示, 将输入稀疏矩阵S进行BSA重排, 生成的重排稀疏矩阵$S_R$进行分块(Tiling),&#13;
根据分块后的块(Tiled)的密度将块分为两类: **稠密块$S_d$**和**稀疏剩余$S_s$**.&#13;
&#13;
将稠密块Sd以Blocked-ELL格式储存, 在Tensor Cores上与稠密矩阵D进行矩阵乘法运算.&#13;
将稀疏剩余Ss以CSR格式储存, 在常规CUDA核心上与稠密矩阵D进行矩阵乘法运算.&#13;
&#13;
最终将两个结果合并后生成最终的输出矩阵O.&#13;
&#13;
---&#13;
&#13;
### 离散度(Dispersions)&#13;
&#13;
在重排序过程前, 通过计算每行中每个列块的非零元素数量, 将其一一储存以生成一组编码向量, 称为Encodings.&#13;
为每一行生成一组离散度, 称为Dispersions. 离散度是基于非零列块的数量和零填充的数量来定义的,&#13;
表示非零元素在行中的分散程度: $\tau\times nnzb+zf$, 其中 $\tau$ 表示每行中列块的大小, $nnzb$ 表示具有非零元素的列块的数量,&#13;
$zf$ 表示一行中具有非零元素的列块的零填充的数量.&#13;
**一行具有高离散度的话, 意味着其非零元素高度分散在多个列块中.**&#13;
**相反, 当一行具有低离散度时, 非零元素主要集中在特定的列块中.**&#13;
Encodings和Dispersions均通过CUDA内核中的并行归约计算.&#13;
&#13;
![离散度计算的两行示例](/img/[论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法/离散度计算的两行示例.png)&#13;
离散度计算的两行示例&#13;
&#13;
**离散度有助于识别和聚类具有相似块稀疏性的行, 从而优化数据局部性. 根据离散度(Dispersions)将行索引按升序排序, 可以提高聚类的效率.&#13;
具有相似块稀疏性的行(即零元素在列块中的分布相似)更有可能被聚类到一起.** 排序结果储存在ascending中.&#13;
&#13;
具体来说, 排序是为了当一个行作为候选行被分组到某个簇中时, 如果比另一个具有更多离散非零元素的行更分散, 则优先考虑.&#13;
空行的离散度为0, 分配一个簇ID为-1以排除所有空行.&#13;
&#13;
&gt; 在数据挖掘和机器学习领域, 簇指的是数据点的集合, 这些数据点在某些特征或属性上彼此相似, 而与其他簇的数据点不同.&#13;
&gt; 聚类分析(Clustering)是一种将数据集中的对象分组的算法, 目的是使同一个簇内的对象相似度高, 而不同簇之间的对象相似度低.&#13;
&#13;
---&#13;
&#13;
### 加权Jaccard相似度&#13;
&#13;
**论文提出的'加权Jaccard相似度(weighted Jaccard similarity)'是'Jaccard相似度'的一种变体. 用于衡量稀疏矩阵中行之间的相似性,&#13;
以便在重排序过程中将相似行聚集在一起形成密集块.**&#13;
&#13;
![公式1](/img/[论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法/公式1.png)&#13;
公式1:加权jaccard相似度&#13;
&#13;
$J(\mathbf{\hat{E}^{rep}},\mathbf{\hat{E}^{cmp}})=\frac{\sum_i\min(E_i^{rep},E_i^{cmp})}{\sum_i\max(E_i^{rep},E_i^{cmp})}$&#13;
&#13;
公式1中, $\mathbf{\hat{E}^{rep}}$ 和 $\mathbf{\hat{E}^{cmp}}$ 表示两个编码的行向量, 每个向量都经过归一化处理,&#13;
以减轻在测量两个向量之间的相似度时向量大小的影响.$E_i^{rep}$ 和 $E_i^{cmp}$ 分别表示 $\mathbf{\hat{E}^{rep}}$&#13;
和 $\mathbf{\hat{E}^{cmp}}$ 中第i个元素. 将$E^{rep}$和$E^{cmp}$视为未归一化的向量, 将 $\mathbf{\hat{E}^{rep}}$&#13;
和 $\mathbf{\hat{E}^{cmp}}$ 视为归一化的向量.&#13;
&#13;
&gt; 编码行向量: 将矩阵的一行划分为大小为 $\tau$ 的列块, 记录每个块中非零元素的数量.&#13;
&#13;
**用上节中离散度计算的两行例子来计算加权Jaccard相似度:**&#13;
&#13;
- $E^{rep}$ : [8, 10, 18, 0, 3]&#13;
- $E^{cmp}$ : [1, 20, 0, 14, 0]&#13;
&#13;
1. 先对其进行归一化:&#13;
    - norm rep = $\sqrt{8^{2} + 10^{2} + 18^{2} + 0^{2} + 3^{2}}\approx22.3$&#13;
    - norm cmp = $\sqrt{1^{2} + 20^{2} + 0^{2} + 14^{2} + 0^{2}}\approx24.4$&#13;
    - $\mathbf{\hat{E}^{rep}}$ : [0.35, 0.45, 0.81, 0, 0.13]&#13;
    - $\mathbf{\hat{E}^{cmp}}$ : [0.04, 0.89, 0, 0.63, 0]&#13;
2. 对每一对数据, 计算它们的最大值和最小值:&#13;
    - 对于第一对 (0.35, 0.04): 最小值是 0.04, 最大值是 0.35&#13;
    - 对于第二对 (0.45, 0.89): 最小值是 0.45, 最大值是 0.89&#13;
    - 对于第三对 (0.81, 0): 最小值是 0, 最大值是 0.81&#13;
    - 对于第四对 (0, 0.63): 最小值是 0, 最大值是 0.63&#13;
    - 对于第五对 (0.013, 0): 最小值是 0, 最大值是 0.013&#13;
3. 计算所有最小值和最大值的总和:&#13;
    - $\sum_i\min(E_i^{rep},E_i^{cmp})$ = 0.04 + 0.45 + 0 + 0 + 0 = 0.49&#13;
    - $\sum_i\max(E_i^{rep},E_i^{cmp})$ = 0.35 + 0.89 + 0.81 + 0.63 + 0.013 = 2.692&#13;
4. 将最小值总和除以最大值总和得到$J$值:&#13;
    - $J(\mathbf{\hat{E}^{rep}},\mathbf{\hat{E}^{cmp}})$ = $\frac{0.49}{2.692}\approx0.1821$&#13;
&#13;
这个$J$值表示两行之间的相似度. 值越接近1, 表示相似度越高. 在这个例子中, $J$值约为0.1821, 表明两行之间的相似度较低.&#13;
**要确定两行是否足够相似, 需要确定一个相似阈值$(\alpha)$, 超过这个阈值则将其认为是相似的, 低于这个阈值认为是不相似的.**&#13;
&#13;
---&#13;
&#13;
### BSA重排序中的相似性度量&#13;
&#13;
生成包含大量非零元素的密集块对于充分利用Tensor core 进行SpMM至关重要.&#13;
为了获得高密度块, 关键是对每行的非零模式的相似性使用每个非零元素的列索引进行聚类. 此后, 将每行的非零列块表示为包含非零元素的列块.&#13;
在重排序矩阵后提取密集块时, 使用与列块大小相同的密集块大小来增强数据局部性.&#13;
&#13;
---&#13;
&#13;
### GPU加速的BSA重排序算法&#13;
&#13;
生成包含大量非零元素的密集块对于充分利用Tensor core进行SpMM至关重要. 为了获得高密度块, 关键是对每行的非零模式的相似性使用每个非零元素的列索引进行聚类.&#13;
算法1展示了host端的整个BSA重排序过程的伪代码.&#13;
&#13;
![算法1](/img/[论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法/算法1.png)&#13;
算法1:整个BSA重排序过程的伪代码&#13;
&#13;
算法第4-9行: 遍历矩阵所有行索引, 如果当前行的离散度为0, 则分配一个簇ID为-1, 以排除所有空行.&#13;
&#13;
第11行 `BSA_clustering()` 为CUDA核函数, 用于比较各个行来产生簇. GPU实现的关键挑战在于, 所需的线程块数量是未知的,&#13;
在聚类开始之间无法确定簇的数量. 为了解决这个问题, 使用CUDA动态并行技术. CUDA动态并行允许在核函数内部调用新的内核,&#13;
并能够将新生成的内核与之前运行的内核并行执行. 通过利用动态并行, 在当前线程块正在执行时, 如果产生了新的簇, 则调用一个新的内核,&#13;
通过添加一个新的线程块来生成新的簇. 所以在11行最初调用CUDA内核时只启动一个线程块, 其他内核将在核函数内部使用CUDA动态并行技术调用.&#13;
最后通过将具有相同簇的行聚集在一起, 保持相同簇内的升序, 得到最终的排序行索引P.&#13;
&#13;
&gt; CUDA动态并行技术(CUDA Dynamic Parallelism)是NVIDIA在其CUDA编程模型中引入的一项特性, 它允许在GPU上运行的内核(kernel)&#13;
&gt; 直接在设备端启动新的内核. 类似于递归.&#13;
&#13;
下图展示了在GPU上的BSA重排序总流程.&#13;
&#13;
![/img.png](/img/[论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法/GPU上对BSA重排序的总体流程.png)&#13;
GPU上对BSA重排序的总体流程&#13;
&#13;
BSA重排序算法使用GPU的主要优点是支持并行聚类和加速编码行向量之间的相似度计算.&#13;
GPU中的单个线程块为每个簇执行相似行的分组, 因此, 多个线程块并行地为各自的簇对行进行聚类.&#13;
如图(a)所示, 每个线程块持续计算代表性编码行向量,&#13;
&#13;
GPU实现的关键挑战在于, 所需的线程块数量是未知的, 在聚类开始之间无法确定簇的数量. 为了解决这个问题, 使用CUDA动态并行技术.&#13;
CUDA动态并行允许在核函数内部调用新的内核, 并能够将新生成的内核与之前运行的内核并行执行.&#13;
通过利用动态并行, 在当前线程块正在执行时, 调用一个新的内核, 通过添加一个新的线程块来生成一个新的簇.&#13;
&#13;
如图(b)所示, 基于相似阈值 $(\alpha)$, 第一个线程对行进行聚类, 形成第一个簇(Cluster 0).&#13;
&#13;
![BSA_clustering()kernel图示](/img/[论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法/BSA_clustering()kernel图示.png)&#13;
&#13;
如果 $\mathbf{\hat{E}^{cmp}}$ 和其候选簇的代表 $\mathbf{\hat{E}^{rep}}$ 相似, 则将 $\mathbf{\hat{E}^{cmp}}$ 分组到与&#13;
$\mathbf{\hat{E}^{rep}}$ 相同的簇中.&#13;
&#13;
如果 $\mathbf{\hat{E}^{cmp}}$ 和其候选簇的代表 $\mathbf{\hat{E}^{rep}}$ 不同, 则创建额外的线程块用以生成新簇.&#13;
&#13;
1. 图(b)-1: $\mathbf{\hat{E}^{cmp}}$ 称为新簇的代表性编码向量 $\mathbf{\hat{E}^{rep}}$.&#13;
   然后新创建的第二个线程块按照升序依次将其自身的 $\mathbf{\hat{E}^{rep}}$ 与其他分散度高于 $\mathbf{\hat{E}^{rep}}$&#13;
   的 $\mathbf{\hat{E}^{cmp}}$ 进行比较.&#13;
2. 图(b)-2: 但是跳过与已分配到其他簇的任何 $\mathbf{\hat{E}^{cmp}}$ 的比较. 如果 $\mathbf{\hat{E}^{cmp}}$ 与&#13;
   第二个簇的 $\mathbf{\hat{E}^{rep}}$ 不同,&#13;
3. 图(b)-3: 当前内核会反复调用新内核, 以利用额外的线程块创建下一个簇:第三个簇(Cluster 2).&#13;
4. 图(b)-4: 在对所有行进行聚类之后, 通过按每个簇内的分散度升序重新排列行索引, 生成存储关于排列行索引的信息P.&#13;
&#13;
算法2展示了BSA聚类核函数的伪代码, 它在GPU上执行BSA重排序.&#13;
&#13;
![算法2](/img/[论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法/算法2.png)&#13;
&#13;
BSA聚类核函数通过利用并行归约合动态并行性以及同步方案实现了高度的并行性.&#13;
每个线程块负责形成一个簇并识别与簇的 $\mathbf{\hat{E}^{rep}}$ 相似的 $\mathbf{\hat{E}^{cmp}}$ 向量.&#13;
核函数中, 使用共享内存来维护 $E^{rep}$, 因为他在每个线程块中经常被引用以计算相似度.&#13;
通过适应CUDA编程指南中提供的`__nanosleep()` 函数来实现互斥锁和互斥解锁函数,&#13;
以避免在将 $\mathbf{\hat{E}^{cmp}}$ 分配给另一个簇时出现同步问题, 从而跳过相似度的比较(第9-12行).&#13;
在计算两个向量之间的加权Jaccard相似度时, 使用线程束的shuffle和共享内存进行并行归约操作,&#13;
以获得 $\mathbf{\hat{E}^{rep}}$ 和$\mathbf{\hat{E}^{cmp}}$ 的范数值(第18行).&#13;
&#13;
- 如果确定 $\mathbf{\hat{E}^{cmp}}$ 与 $\mathbf{\hat{E}^{rep}}$ 相似, 则分配 $\mathbf{\hat{E}^{cmp}}$ 的相应簇ID(cid),&#13;
  并通过累加 $\mathbf{\hat{E}^{cmp}}$ 来动态更新 $\mathbf{\hat{E}^{rep}}$ 的值(第25-28行).&#13;
- 否则采用动态并行方案, 当前线程块中的仅一个线程调用一个新内核, 使用一个线程块生成下一个簇(第30-33行).&#13;
&#13;
鉴于多个线程块同时执行以处理多个簇, 需要同步其他内核以防止不止一个线程块比较同一行的情况.&#13;
因此当线程块分配其唯一的 $E^{rep}$ (第5行) 并依次将 $\mathbf{\hat{E}^{cmp}}$ 与 $\mathbf{\hat{E}^{rep}}$ 进行比较时(&#13;
第8-32行),&#13;
使用行互斥锁(正对行的互斥锁集合)以及互斥函数. 此块, 互斥锁的使用确保每个簇只能使用一个线程块, 从而避免多个线程同时锁定导致出现的同步问题.&#13;
&#13;
---&#13;
&#13;
### 密集矩阵块的确定&#13;
&#13;
重排序算法是基于块稀疏模式对行进行排序, 排序后的稀疏矩阵可能呈现出一种块结构, 非零元素集中在特定的列块中的多行内.&#13;
但也有可能存在少量非零元素任然不规则的放置在排序好的矩阵中.&#13;
为了避免在Tensor Cores上处理这些稀疏分布的非零元素, 将重新排序后的矩阵中的密集块和稀疏剩余分开.&#13;
将大小为M×K的重新排序矩阵划分为 $M / \tau \times K / T$ 个大小为 $\tau \times \tau$ 的块,&#13;
并根据非零密度阈值 $\delta$ 来确定大小为 $\tau \times \tau$ 的块是否为稠密块.&#13;
由于调整 $\delta$ 的值与在Tensor Cores上处理密集块的数量密切相关, 根据不同的稀疏矩阵的性能明智地选择最优的 $\delta$ 值.&#13;
&#13;
---&#13;
&#13;
### 压缩Blocked-ELL格式以降低复杂性.&#13;
&#13;
在对矩阵进行重新排序后, 重新排序后的矩阵 $S_R$ 被分为稠密块 $S_d$ 和稀疏剩余 $S_s$. 为了同时使用Tensor Cores处理 $S_d$&#13;
中的密集块,&#13;
采用NVIDIA的cuSPARSE Block-SpMM, 使用Blocked-ELL格式和 'cusparseSpMM()' 函数间接利用Tensor Cores进行并行块矩阵乘法.&#13;
$S_D$ 中的密集块元素是以Block-edELL格式储存, 为了匹配重新排序期间使用的列块大小 $\tau$, 密集块大小定为 $\tau\times\tau$.&#13;
&#13;
因为最初将所有空行重新排列到排序后的矩阵的前面, 能够进一步压缩Blocked-ELL格式.&#13;
将cuSPARSE Block-SpMM的起始指针配置为从Blocked-ELL格式中第一个非零块的出现开始使用Tensor cores进行计算.&#13;
&#13;
对于稀疏剩余 $S_s$ 中的非零元素, 使用CSR格式储存, 以便在CUDA核心上使用NVIDIA的cuSPARSE进行SpMM操作.&#13;
&#13;
$S_p$ 和 $S_s$ 分别独立用于执行SpMM操作, 最后将两个结果合并生成最终的输出矩阵 $O$.&#13;
&#13;
---&#13;
&#13;
## 实验评估&#13;
&#13;
- CPU: 12th Gen Intel(R) Core(TM) i7-12700 (12个物理核心)&#13;
- GPU: NVIDIA RTX 3080 GPU (69个安培SM, 计算能力为8.6, 10GB显存, 带宽为760GB/s).&#13;
- NVCC 12.1编译CUDA, 采用O3优化. C++11标准.&#13;
&#13;
- 数据集:&#13;
    - Deep Learning Matrix Collection(DLMC)的稀疏矩阵, 稀疏度范围从50%到90%.&#13;
    - 通过应用各种剪枝技术到Transformer和ResNet-50模型中生成的2587个非结构化稀疏矩阵.&#13;
        - Transformer稀疏矩阵的行数(M)从512到33288不等&#13;
        - RenNet-50稀疏矩阵的行数(M)从64到2048不等&#13;
    - SuiteSparse矩阵集合的不同大小的稀疏矩阵, 主要包含稀疏度超过90%的稀疏矩阵&#13;
&#13;
---&#13;
&#13;
### 性能评估&#13;
&#13;
![从DLMC收集的稀疏矩阵上的SpMM的性能比较](/img/[论文笔记]高效的块稀疏感知(BSA)矩阵重排序方法以充分利用张量核心加速稀疏矩阵-多向量乘法/从DLMC收集的稀疏矩阵上的SpMM的性能比较.png)&#13;
从DLMC收集的稀疏矩阵上的SpMM的性能比较. X轴: 稀疏矩阵的稀疏度; Y 轴：以 cuBLAS 为基准并结合 Tensor core&#13;
进行归一化处理后的加速比（黑色虚线水平线). 每个方框中的黑线表示中位加速倍数.&#13;
&#13;
上图展示了BSA-SpMM与其他SpMM实现之间的加速比较, 其中以cuBLAS为基准, 用黑色虚线表示. 所有实验结果都是基于10次不同的执行取平均值得出的.&#13;
在BSA-SpMM中, 使用固定的分块大小$(\tau)$为32, 并为每个实验选择了最佳的分块密度阈值$(\delta)$.&#13;
如图所示, BSA-SpMM实现了平均2.01倍的加速, 超过了cuBLAS.&#13;
&#13;
实验表明, 当使用具有50%到70稀疏性的稀疏矩阵时, BSA-SpMM在所有稀疏矩阵上的表现始终优于其他SpMM实现. 然而, 当保持更高的稀疏性时,&#13;
识别不规则的非零模式并利用Tensor Cores进行SpMM就变得更加困难. 由于BSA-SpMM通过cuSPARSE库处理重新排序矩阵中的稀疏剩余,&#13;
当稀疏度达到90%时,&#13;
在不重新排序的情况下, cuSPARSE的方法会收敛. 然而, 对于超过90%稀疏度的稀疏矩阵, BSA-SpMM实现了平均1.98倍的加速,&#13;
超过了cuSPARSE.&#13;
&#13;
---&#13;
&#13;
## 总结&#13;
&#13;
由于SpMM中非零元素的不规则分布和产生的内存访问模式, 使用非结构化稀疏矩阵进行SpMM具有挑战性. 论文中, 开发了一种新颖的重排序算法,&#13;
通过在行聚类过程中考虑块稀疏模式来增强SpMM的数据局部性. 并且开发了一种高效地GPU实现, 动态并行地聚类行. 最终实验结果表明,&#13;
BSA-SpMM与现有的最先进SpMM实现相比, 获得了最高21.99倍的加速.&#13;
&#13;
论文链接: [Accelerated Block-Sparsity-Aware Matrix Reordering for Leveraging Tensor Cores in Sparse Matrix-Multivector Multiplication](https://link.springer.com/chapter/10.1007/978-3-031-69583-4_1)&#13;
&#13;
开源链接: [BSA-SpMM_EURO-PAR-2024](https://github.com/dleunji/BSA-SpMM_EURO-PAR-2024)&#13;
&#13;
---。</description><guid isPermaLink="true">https://CX9898.github.io/post/gao-xiao-de-kuai-xi-shu-gan-zhi-%28BSA%29-ju-zhen-zhong-pai-xu-fang-fa-yi-chong-fen-li-yong-zhang-liang-he-xin-jia-su-xi-shu-ju-zhen---duo-xiang-liang-cheng-fa.html</guid><pubDate>Wed, 01 Jan 2025 10:20:05 +0000</pubDate></item><item><title>CUDA 编程使用 Tensor core 详解</title><link>https://CX9898.github.io/post/CUDA%20-bian-cheng-shi-yong-%20Tensor%20core%20-xiang-jie.html</link><description>![Tensor core](/img/CUDA_编程使用_Tensor_core_详解/封面.png)&#13;
&#13;
# CUDA 编程使用 Tensor core 详解&#13;
&#13;
前言&#13;
&#13;
最近在学习怎么使用 Tensor core.&#13;
主要通过 [NVIDIA 官方文档](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#warp-matrix-functions)和&#13;
[cuda-samples](https://github.com/NVIDIA/cuda-samples) 项目中关于 Tensor core 部分的实际代码示例结合其他文章做出总结,&#13;
再结合使用过程中的一些问题写出这篇文章.&#13;
本文首先解释了什么是 Tensor core 再详细说明在实际编程中如何使用 Tensor core.&#13;
&#13;
文章链接 : [CUDA 编程使用 Tensor core 详解](https://zhuanlan.zhihu.com/p/706494789)&#13;
&#13;
---&#13;
&#13;
## 什么是 Tensor core&#13;
&#13;
在 2017 GPU 技术大会(GTC 2017)上, NVIDIA推出了新一代 Volta 架构,&#13;
以及使用新架构的第一款设备 : 适用于深度学习任务的加速卡 Tesla V100.&#13;
Tesla V100 GPU架构首次搭搭载了张量核心(Tensor core).&#13;
Volta 架构中每一个 SM 中在固有的 CUDA core 基础上额外搭载了8个 Tensor core.&#13;
**Tensor core 主要设计用于加速矩阵计算.**&#13;
&#13;
![Tesla V100单个SM架构图](/img/CUDA_编程使用_Tensor_core_详解/Tesla_V100单个SM架构图.png)&#13;
&lt;p style='text-align:center'&gt;Tesla V100单个SM架构图&lt;/p&gt;&#13;
&#13;
**Tensor Core 是执行矩阵乘法累加的运算单元, 并且是混合精度的计算.&#13;
将两个半精度(FP16)矩阵相乘, 并将结果累积到一个累加矩阵中.**&#13;
&#13;
![Tensor core中的混合精度相乘和累加操作](/img/CUDA_编程使用_Tensor_core_详解/Tensor_Core_执行4x4x4矩阵相乘累加.png)&#13;
&lt;p style='text-align:center'&gt;Tensor Core 执行4x4x4矩阵相乘累加&lt;/p&gt;&#13;
&#13;
每个 Tensor Core 每时钟周期能执行 4x4x4 个矩阵运算, 执行运算 **D = A * B + C**, 其中 **A, B, C, D 是 4×4 矩阵**.&#13;
A, B是半精度(FP16)的矩阵, 累加矩阵C, D可以是半精度(FP16)或单精度(FP32)的矩阵.&#13;
&#13;
&gt; 混合精度计算是指在底层硬件算子层面, 使用半精度(FP16)作为输入和输出, 使用全精度(FP32)进行中间结果计算和保存从而不损失过多精度的技术.&#13;
&#13;
![Tensor core中的混合精度相乘和累加操作](/img/CUDA_编程使用_Tensor_core_详解/Tensor_core_中的混合精度相乘和累加操作.png)&#13;
&lt;p style='text-align:center'&gt;Tensor core 中的混合精度相乘和累积操作&lt;/p&gt;&#13;
&#13;
---&#13;
&#13;
## 为什么使用 Tensor core&#13;
&#13;
Tesla V100 单个 SM 架构图中可以看到, 单个 SM 中分为4个 sub core.&#13;
一个 sub core 中的 CUDA core 单个时钟周期可以执行 16 次 FFMA 操作.&#13;
**一个 sub core 中有两个 Tensor core, 单个 Tensor core 每个时钟可以执行 64 次 FFMA 混合精度运算(FP16 乘法与 FP32&#13;
累加). **&#13;
比起 CUDA core, 使用 Tensor core 的吞吐量提升了8倍.&#13;
&#13;
&gt; FFMA(Fused Floating-Point Multiply-Add)是一种在 GPU 上执行的高效数学运算,&#13;
&gt; 将 32 位浮点数的乘法和加法两个操作融合在一个指令中完成, 从而提高性能和减少计算延迟.&#13;
&#13;
Tesla V100 在一个 SM 单元中有8个 TensorCore, 每个时钟可执行共计 1024 次浮点运算.  &#13;
使用 Volta 架构的 V100 GPU 相比于上一代 Pascal 架构的 P100 GPU 的吞吐量一共提升了 12 倍.&#13;
&#13;
![Pascal架构和Volta架构矩阵运算速度对比](/img/CUDA_编程使用_Tensor_core_详解/Pascal架构和Volta架构矩阵运算速度对比.gif)&#13;
&lt;p style='text-align:center'&gt;Pascal架构和Volta架构矩阵运算速度对比&lt;/p&gt;&#13;
&#13;
CUDA core 中, 每次进行一个点和一行进行相乘依次得到新的矩阵, 而 Tensor core 中是一个矩阵和另一个矩阵直接相乘得到新的矩阵.&#13;
&#13;
&gt; 运算从依次从一行和一列进行相乘得到结果,变化到一个矩阵与另一个矩阵直接相乘得到结果, 则编程思路也要进行变化.&#13;
&gt; 下一节说明使用 Tensor core 的思路.&#13;
&#13;
---&#13;
&#13;
## 分块(tilling)&#13;
&#13;
矩阵乘法一般使用分块 (tilling) 技术将大矩阵划分为许多小块 (tile) 分别进行计算,&#13;
通过对小块矩阵进行乘法运算, 降低了算法的时间复杂度, 并能够更好地利用缓存.&#13;
**而每一个结果矩阵的块 (tile) 都是由**&#13;
**两个相乘矩阵 (A, B矩阵) 的块 (tile) 沿着 K 维度 (A矩阵的行, B矩阵的列) 相乘并累加得到的.**&#13;
&#13;
![计算和储存匹配CUDA模型的分层结构](/img/CUDA_编程使用_Tensor_core_详解/计算和储存匹配CUDA模型的分层结构.png)&#13;
&lt;p style='text-align:center'&gt;计算和储存匹配CUDA模型的分层结构&lt;/p&gt;&#13;
&#13;
分块技术将 A, B 和 C 矩阵按照相对应的维度 (例如 C 块的维度是 m × n, A 块是 m × k, B 块是 k × n) 分为无数个小的矩阵块.&#13;
一个 m × n 的 C 块的结果由对应 m × k 的 A 块 和 k × n 的 B 块沿着 K 维相乘并累加得到.&#13;
&#13;
如下图所示, 要计算一个 32 × 8 的 C 块, 它在结果矩阵 C 的位置是最左上角, 也就是由1~32行和1~8列组成的矩阵块.&#13;
设 k = 16, 则首先计算A矩阵的第0~31行和第0~15列组成的A块与B矩阵的第0~15行和第0~7列组成的B块相乘得到中间结果矩阵acc(&#13;
accumulator-1)块,&#13;
再计算由第0~31行和第16~31列组成的A块与第16~31行和第0~7列组成的B块相乘得到的新的acc(accumulator-2)块与上一次的acc(&#13;
accumulator-1)块做矩阵加法.&#13;
沿K维循环迭代进行, 最终遍历计算 A 矩阵第0~31行的所有数据和 B 矩阵第0~7列的所有数据得到最终结果矩阵 C 块.&#13;
&#13;
![分块矩阵相乘累加示例.png](/img/CUDA_编程使用_Tensor_core_详解/分块矩阵相乘累加示例.png)&#13;
&lt;p style='text-align:center'&gt;分块矩阵相乘累加示例&lt;/p&gt;&#13;
&#13;
**使用分块技术来计算矩阵乘法最主要的操作就是两个矩阵块相乘, 将结果矩阵块累加到上一次的结果矩阵块.&#13;
Tensor core 就是用于计算矩阵相乘和累加的操作.**&#13;
&#13;
将矩阵按照 Tensor core 支持的矩阵维度来分块, 随后将 A 块 和 B 块利用 Tensor core 沿着 K 维相乘累加得到结果矩阵 C 块.&#13;
再进行同样的操作来计算下一个 C 块, 最后所有的 C 块结合起来得到最终的结果矩阵.&#13;
&#13;
&gt; 也可以通过使用 cuBLAS 和 cuDNN 这两个 CUDA 库来间接使用 Tensor Cores.&#13;
&gt; cuBLAS 利用 Tensor Cores 加速密集矩阵乘法(GEMM)计算;&#13;
&gt; cuDNN 则利用 Tensor Cores 加速卷积和循环神经网络(RNNs)的计算.&#13;
&#13;
---&#13;
&#13;
## WMMA API&#13;
&#13;
CUDA 9.0 引入了一个以 warp 级别进行操作的矩阵计算函数, 以便开发者可以使用 GPU 上的 Tensor Core.&#13;
称为WMMA(Warp-level Matrix Multiply and Accumulate)API.&#13;
通过 WMMA API, 可以将 D = A × B + C 运算使用 warp 级别进行操作,&#13;
其中的A、B、C、D都是更大矩阵的块(tile). 也就是可以使用一个 warp (32个线程) 来计算一个结果矩阵块.&#13;
&#13;
**实际工作中, 一个warp中的每个线程都只计算结果矩阵块的8个数据(16×16/32).**&#13;
&#13;
Tensor core 支持各种元素类型和矩阵维度, 下表列出了目前WMMA API支持的 matrix_a, matrix_b 和 accumulator 矩阵的部分格式和矩阵维度.&#13;
&#13;
![Tensor core WMMA API 目前支持的格式和矩阵维度](/img/CUDA_编程使用_Tensor_core_详解/Tensor_core_WMMA_API_目前支持的格式和矩阵维度.png)&#13;
&lt;p style='text-align:center'&gt;Tensor core WMMA API 目前支持的格式和矩阵维度&lt;/p&gt;&#13;
&#13;
&gt; 这里只列出部分常用格式.&#13;
&gt; Tensor core 还支持特殊格式, 详细可在官网查看 :&#13;
&gt; [CUDA C++ Programming Guide 7.24.6. Element Types and Matrix Sizes](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#element-types-and-matrix-sizes)&#13;
&#13;
要通过 WMMA API 来使用 Tensor core 只需要简单4个步骤 :&#13;
&#13;
- 首先创建用于储存矩阵块的 fragment 类&#13;
- 将矩阵块读取到 fragment 类中&#13;
- 进行矩阵乘法累加计算&#13;
- 最后将计算结果写回到结果矩阵&#13;
&#13;
&gt; 调用前需要检查 GPU 是否带有 Tensor core, 并且在构建项目时设置对应的 GPU 架构.&#13;
&gt; 构建方式可以查看另一篇文章 : [用 CMake 构建跨平台 CUDA C/C++ 项目](https://zhuanlan.zhihu.com/p/701581020)&#13;
&#13;
WMMA API的所有函数和类型都在头文件 `mma.h` 中的 `namespace::nvcuda::wmma` 命名空间中定义.&#13;
为了简化代码的同时避免命名空间冲突, 保持 `wmma` 的显示, 只使用 `nvcuda` 命名空间.&#13;
&#13;
```C++&#13;
#include &lt;mma.h&gt;&#13;
using namespace nvcuda;&#13;
```&#13;
&#13;
---&#13;
&#13;
### fragment 类&#13;
&#13;
**fragment 是一个重载类, 用于储存矩阵片段(块)的数据.**&#13;
&#13;
```C++&#13;
template&lt;typename Use, int m, int n, int k, typename T, typename Layout=void&gt; class fragment;&#13;
&#13;
// examples&#13;
wmma::fragment&lt;wmma::matrix_a, WMMA_M, WMMA_N, WMMA_K, half, wmma::row_major&gt; aFrag;&#13;
wmma::fragment&lt;wmma::matrix_b, WMMA_M, WMMA_N, WMMA_K, half, wmma::col_major&gt; bFrag;&#13;
wmma::fragment&lt;wmma::accumulator, WMMA_M, WMMA_N, WMMA_K, float&gt; cFrag;&#13;
```&#13;
&#13;
- `Use` : 用作第一个乘数的矩阵使用 `matrix_a` , 第二个乘数的矩阵使用 `matrix_b` . 当分别用作累加器C或目标累加器D时使用&#13;
  `accumulator`&#13;
- `m` , `n` , `k` : 表示参与乘法和累积操作的矩阵块的形状, 比如说矩阵A块是m×k, 矩阵B块是k×n, 矩阵C块是m×n&#13;
- `T` : 使用的数据类型. `double` , `float` , `__half` , `__nv_bfloat16` , `char` , `unsigned char`&#13;
- `Layout` : 表示矩阵是以行主序 `row_major` 或列主序 `col_major` 的形式保存在内存中, 当 `Use` 参数使用 `accumulator`&#13;
  时则不需要填写,&#13;
  默认是列主序储存&#13;
&#13;
成员变量 `num_elements` 记录元素总数, 一般为8. 配合成员变量 `x` 可以遍历所有元素. 例如让储存的所有元素乘2 :&#13;
&#13;
```C++&#13;
for (int idx = 0; idx &lt; frag.num_elements; ++idx) {&#13;
    frag.x[idx] *= 2;&#13;
}&#13;
```&#13;
&#13;
官方文档(CUDA C++ Programming Guide)中关于fragment类的描述说 'The mapping of matrix elements into fragment internal&#13;
storage is unspecified and subject to change&#13;
in future architectures.'&#13;
也就是说通过以上方式不能准确知道遍历过程中当前 `idx` 下的 `frag.x[idx]` 在实际矩阵块中的哪个位置.&#13;
&#13;
但是实际可以直接通过将同一个warp中的每个线程(lane)储存的元素全部打印出来对照查看就能知道.&#13;
以下列表是当m,n,k都分别设置为16的情况下每个线程储存原始矩阵的位置.&#13;
&#13;
&gt; Warp是CUDA中最小的执行单元, 它由一组固定数量的线程组成(在NVIDIA的Fermi架构及以后的GPU中, 一个warp包含32个线程).&#13;
&gt; 同一个warp中, 每个线程被称为一个'lane', 术语来自于'车道'的比喻, 就像在高速公路上, 每个车道可以独立行驶一辆车.&#13;
&gt; 每个lane可以看作是一个独立的执行路径, 它们共享warp的执行状态, 但各自有自己的寄存器和执行流.&#13;
&#13;
![m16n16k16情况下,部分线程fragment类中储存的原矩阵块C的元素位置.png](/img/CUDA_编程使用_Tensor_core_详解/m16n16k16情况下,部分线程fragment类中储存的原矩阵块C的元素位置.png)&#13;
&lt;p style='text-align:center'&gt;m16n16k16情况下, 部分线程fragment类中储存的原矩阵块C的元素位置. 行标为laneId, 列标为fragment类的Index. 数据为[row,col]&lt;/p&gt;&#13;
&#13;
通过上图可以发现一些规律:&#13;
&#13;
1. 从每个线程储存的行数上看, 线程的每两个Index储存相同的行元素, 并且Index为0~1和4~5储存了相同的行元素, 2~3和6~&#13;
   7储存了相同的行元素. 也就是每个线程只储存了两个行元素, 并且相差为8, 0~1和4~5是小一些的行数.&#13;
2. 从每个线程储存的列数上看, 线程的每两个Index储存连续的两列元素, 并且Index为0和2储存了相同的列元素, 1和3储存了相同列元素.&#13;
   也就是每个线程储存了4个列元素, 并且每两个列元素相差为8, 前4个Index储存了小一些的列数.&#13;
3. 从每个线程储存的列数与Index对比, 发现Index为偶数时, 储存的列数也为偶数, Index为奇数时, 储存的列数也为奇数.&#13;
4. 原矩阵同一行的数据由每连续的4个线程储存.&#13;
5. 0到15行数据中, 行数以8为分界线, T0储存第0行和第8行的元素, 之后根据规律③增加.&#13;
6. 0到15列数据中, 列数以8为分界线, 每个线程的每两个Index储存连续的2列的元素. 根据规律③的4个线程为一组, 组内第0号线程,&#13;
   储存0,1,8,9列元素, 第1号线程储存2,3,10,11列元素, 以此类推.&#13;
&#13;
例如要找到原矩阵块中第1行第12列的是在哪个线程储存, 储存的Index是多少?&#13;
可以先**通过行数, 根据第④和第⑤条规律计算出从哪个线程ID开始储存**.&#13;
&#13;
```C++&#13;
const int startLane = localRow % 8 * 4;&#13;
```&#13;
&#13;
从以上公式算出[1,12]是由第4号开始的线程储存, 也就是4~7线程储存了第1行元素.&#13;
&#13;
再**通过列数, 根据第④和第⑥条规律计算出在连续四个线程中的哪个线程储存了该元素**. 最终得到线程(lane)ID.&#13;
&#13;
```C++&#13;
laneId = startLane + localCol % 8 / 2;&#13;
```&#13;
&#13;
从以上公式算出[1,12]是由第6号线程储存. 知道了线程Id之后还需要知道属于fragment类中的哪个Index储存.&#13;
&#13;
最后**根据第①, ②和③条规律计算出元素所在fragment类中的Index**.&#13;
&#13;
```C++&#13;
const int isBigRow = localRow / 8;&#13;
const int isBigCol = localCol / 8;&#13;
index = isBigCol * 4 + isBigRow * 2 + localCol % 2;&#13;
```&#13;
&#13;
最终得到第1行第12列的数据由fragment类的Index为4的第6号线程储存.&#13;
&#13;
以上规律虽然说可能会在未来的架构中改变, 但是在短时间内大概率不会进行更改. 并且未来更改了也可以根据这样的方式找到计算的方法.&#13;
&#13;
---&#13;
&#13;
### 加载矩阵数据&#13;
&#13;
`load_matrix_sync()` 函数用于从内存加载矩阵的片段到 fragment 类中. 并且**开始前会进行线程同步(sync)操作.**&#13;
&#13;
```C++&#13;
void load_matrix_sync(fragment&lt;...&gt; &amp;a, const T* mptr, unsigned ldm);&#13;
void load_matrix_sync(fragment&lt;...&gt; &amp;a, const T* mptr, unsigned ldm, layout_t layout);&#13;
```&#13;
&#13;
- `a` : 函数输出. 储存矩阵片段的 fragment 类&#13;
- `mptr` : 必须是一个 256 位对齐的指针, 指向内存中矩阵第一个要加载的元素&#13;
- `ldm` : 表示元素在连续行(行主序时)或列(列主序时)在内存中的跨度. 也就是每行/列的元素数量&#13;
- `layout` : 指定矩阵是以行主序或列主序的形式保存在内存中, 必须指定为行主序 : `mem_row_major` 或列主序 : `mem_col_major`&#13;
&#13;
&gt; 注意 : 因为会进行线程同步操作, 此函数必须由 warp 中的所有线程调用.&#13;
&#13;
如果**要加载的块不满足对应的矩阵维度, 结果将出错**. 也就是说要保证输入矩阵块的大小和 fragment 类的参数相匹配.&#13;
例如指定的fragment类的m,n,k分别为32,8,16, 那么加载的矩阵块A的大小必须是32×16, 矩阵块B的大小必须是16×8.&#13;
&#13;
&gt; 特别是在进行K迭代时, 要注意是否超过了原始矩阵的大小.&#13;
&#13;
---&#13;
&#13;
### 矩阵计算&#13;
&#13;
`mma_sync()` 函数进行矩阵乘法累加计算. 会在**开始前进行线程同步(sync)操作.**&#13;
&#13;
```C++&#13;
void mma_sync(fragment&lt;...&gt; &amp;d, const fragment&lt;...&gt; &amp;a, const fragment&lt;...&gt; &amp;b, const fragment&lt;...&gt; &amp;c, bool satf=false);&#13;
```&#13;
&#13;
- d , a , b , c : 表示对应的矩阵片段&#13;
- satf :  饱和有限值模式, 也就是安全模式. 默认为 `false` , 如果设置为 `true` , 则目标累加器有以下额外的数值属性 :&#13;
    - 如果一个元素的计算结果为正无穷, 则对应的累加器将会包含 `+MAX_NORM`&#13;
    - 如果一个元素的计算结果为负无穷, 则对应的累加器将会包含 `-MAX_NORM`&#13;
    - 如果一个元素的计算结果为 NaN, 则对应的累加器将包含 `+0`&#13;
&#13;
&gt; 矩阵之间片段的形状必须匹配, 也就是参数 `m` , `n` , `k` 需要相匹配.&#13;
&#13;
将 A 块和 B 块相乘, 结果累加到 acc 块中 :&#13;
&#13;
```C++&#13;
mma_sync(accFrag, aFrag, bFrag, accFrag);&#13;
```&#13;
&#13;
&gt; 注意 : 因为会进行线程同步操作, 此函数必须由 warp 中的所有线程调用.&#13;
&#13;
---&#13;
&#13;
### 存储矩阵数据&#13;
&#13;
`store_matrix_sync()` 函数与 `load_matrix_sync()` 函数相反, 是将矩阵片段存储回内存中. 也会在开始前进行线程同步(sync)操作.&#13;
&#13;
```C++&#13;
void store_matrix_sync(T* mptr, const fragment&lt;...&gt; &amp;a, unsigned ldm, layout_t layout);&#13;
```&#13;
&#13;
- `mptr` : 必须是一个256位对齐的指针, 指向数据储存的第一个位置&#13;
- `a` : 源矩阵片段 fragment 类&#13;
- `ldm` : 表示元素在连续行(行主序时)或列(列主序时)在内存中的跨度. 也就是每行/列的元素数量&#13;
- `layout` : 指定矩阵是以行主序或列主序的形式保存在内存中, 必须指定为行主序 `mem_row_major` 或列主序 `mem_col_major`&#13;
&#13;
&gt; 注意 : 因为会进行线程同步操作, 此函数必须由 warp 中的所有线程调用&#13;
&#13;
---&#13;
&#13;
### 填充矩阵数据&#13;
&#13;
`fill_fragment()` 是用于对矩阵片段 `fragment&lt;&gt;` 类进行操作, 可以用常量值 `v` 来填充整个矩阵片段.&#13;
&#13;
```C++&#13;
void fill_fragment(fragment&lt;...&gt; &amp;a, const T&amp; v);&#13;
```&#13;
&#13;
一般用于对创建的 fragment 类进行初始化, 例如将记录中间结果的 acc 块先初始化为 0 :&#13;
&#13;
```C++&#13;
wmma::fragment&lt;wmma::accumulator, WMMA_M, WMMA_N, WMMA_K, float&gt; accFrag;&#13;
wmma::fill_fragment(accFrag, 0.0f);&#13;
```&#13;
&#13;
---&#13;
&#13;
## cuBLAS 库使用 Tensor core&#13;
&#13;
使用 cuBLAS 库先要创建...........&#13;
目前只有 GEMM 操作支持使用 Tensor core, 要使用 Tensor core 需要设置数学模式为 : `CUBLAS_TENSOR_OP_MATH` .&#13;
&#13;
```C++&#13;
cublasSetMathMode(cublasHandle, CUBLAS_TENSOR_OP_MATH);&#13;
```&#13;
&#13;
A, B 和 C 矩阵都默认为列主序储存&#13;
&#13;
参数:&#13;
&#13;
- `CUBLAS_OP_N` : 非转置操作&#13;
- `CUBLAS_OP_T` : 转置操作&#13;
- `CUBLAS_OP_C` : 共轭转置操作&#13;
&#13;
&gt; 共轭转置 : 要理解共轭转置首先要了解什么是实数什么是虚数.&#13;
&gt; 实数是可以在数轴上面表示的数, 也就是平常接触到的数, 可以进行标准的加减乘除操作.&#13;
&gt; 复数是由实数和虚数部分组成的数, 基本形式为 a + b * i ,&#13;
&gt; 其中 a 是实部(可以是任何实数), b 是虚部(可以是任何实数), i 是虚数单位(满足 i² = -1 ).&#13;
&gt; 实数是复数的一个子集(也就是 b = 0 时). 复数在实数系统中无法表示,&#13;
&gt; 复数的引入扩展了数学的边界, 使得能够解决一些在实数范围内无法解决的问题.&#13;
&gt; 而共轭转置就是将一个复数 a + b * i 变为 a - b * i&#13;
&#13;
---&#13;
&#13;
## 示例&#13;
&#13;
下面是使用WMMA API计算稠密矩阵-稠密矩阵乘法的示例. 其中矩阵A和矩阵B的类型为half, 结果矩阵C的类型为float.&#13;
矩阵块维度m,n和k都是16. 所有矩阵都以行主序储存.&#13;
&#13;
```C++&#13;
// According to the planning of cuda thread blocks, &#13;
// calculate the row id and column id of the resulting matrix block C to be computed by the current warp.&#13;
int cRow, cCol;&#13;
&#13;
wmma::fragment&lt;wmma::matrix_a, WMMA_M, WMMA_N, WMMA_K, half, wmma::row_major&gt; aFrag;&#13;
wmma::fragment&lt;wmma::matrix_b, WMMA_M, WMMA_N, WMMA_K, half, wmma::row_major&gt; bFrag;&#13;
&#13;
wmma::fragment&lt;wmma::accumulator, WMMA_M, WMMA_N, WMMA_K, float&gt; accFrag;&#13;
fill_fragment(accFrag, 0.0f);&#13;
&#13;
// All matrices are stored in row-order&#13;
const int lda = K;&#13;
const int ldb = N;&#13;
const int ldc = N;&#13;
&#13;
for (int kIter = 0; kIter &lt; K; kIter += WMMA_K) {&#13;
const int aRow = cRow;&#13;
const int aCol = kIter;&#13;
&#13;
const int bRow = kIter;&#13;
const int bCol = cCol;&#13;
&#13;
// bounds checking&#13;
if (aRow &lt; M &amp;&amp; aCol &lt; K &amp;&amp; bRow &lt; K &amp;&amp; bCol &lt; N) {&#13;
const half* aOffsetPtr = mtrA + aRow * lda + aCol;&#13;
const half* bOffsetPtr = mtrB + bRow * ldb + bCol;&#13;
&#13;
load_matrix_sync(aFrag, aOffsetPtr, lda);&#13;
load_matrix_sync(bFrag, bOffsetPtr, ldb);&#13;
&#13;
mma_sync(accFrag, aFrag, bFrag, accFrag);&#13;
}&#13;
}&#13;
&#13;
float* cOffsetPtr = mtrC + cRow * ldc + cCol;&#13;
&#13;
store_matrix_sync(cOffsetPtr, accFrag, ldc, wmma::mem_row_major);&#13;
```&#13;
&#13;
---&#13;
&#13;
参考:&#13;
&#13;
[1] [Tips for Optimizing GPU Performance Using Tensor Cores](https://developer.nvidia.com/blog/optimizing-gpu-performance-tensor-cores/)&#13;
&#13;
[2] [CUDA C++ Programming Guide:7.24. Warp Matrix Functions](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#warp-matrix-functions)&#13;
&#13;
[3] [NVIDIA TESLA V100 GPU ARCHITECTURE](https://images.nvidia.cn/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf)&#13;
&#13;
[4] [PTX ISA 8.5: 9.7.15.4.1. Matrix Fragments for mma.m8n8k4 with .f16 floating point type](https://docs.nvidia.com/cuda/parallel-thread-execution/#matrix-fragments-for-mma-m8n8k4-with-f16-floating-point-type)。</description><guid isPermaLink="true">https://CX9898.github.io/post/CUDA%20-bian-cheng-shi-yong-%20Tensor%20core%20-xiang-jie.html</guid><pubDate>Thu, 21 Nov 2024 05:37:25 +0000</pubDate></item><item><title>数据库系统概念</title><link>https://CX9898.github.io/post/shu-ju-ku-xi-tong-gai-nian.html</link><description>![img.png](/img/%5B摘要%5D数据库系统概念/封面.png)&#13;
&#13;
# 高级数据库&#13;
&#13;
[Database System Concepts&lt;br&gt;Seventh Edition](https://db-book.com/)&#13;
&#13;
---&#13;
&#13;
## 17章: 交易&#13;
&#13;
概述:&#13;
&#13;
- [交易的概念](#交易的概念)&#13;
- [交易状态](#交易状态)&#13;
- [并发执行](#并发执行)&#13;
- [可串行化](#可串行化)&#13;
- [可恢复性](#可恢复性)&#13;
- [隔离的实施](#隔离的实施)&#13;
- [SQL中的事物定义](#SQL中的事物定义)&#13;
- [可串行化的测试](#可串行化的测试)&#13;
&#13;
### 交易的概念&#13;
&#13;
Transaction Concept&#13;
&#13;
**交易**是程序执行的一个单元, 它访问并且可能更新各种数据项.&#13;
&#13;
为了保证数据的完整性, 数据库系统必须确保:&#13;
&#13;
- 原子性: 要么事务的所有操作都在数据库中得到正确反映, 要么全部操作都不反映&#13;
- 一致性: 孤立地执行一个事务可保持数据库的一致性&#13;
- 隔离性: 尽管多个事务可能并发执行, 但每个事务都必须对其他并发执行的事物一无所知&#13;
- 持久性: 交易成功完成后, 对数据库所做的更改会得以保存, 即便出现系统故障也是如此&#13;
&#13;
### 交易状态&#13;
&#13;
Transaction State&#13;
&#13;
- 活动: 初始状态; 事务在执行期间一直处于此状态&#13;
- 部分提交: 在执行完最后一个语句之后&#13;
- 失败: 在发现正常的执行流程无法继续进行之后&#13;
- 已终止: 在事务已回滚且数据库恢复到事务开始前的状态之后.&#13;
    - 事务终止后有两个选择:&#13;
        - 重新启动交易(只有在没有内部逻辑错误的情况下)&#13;
        - 终止交易&#13;
- 已提交: 在成功完成之后&#13;
&#13;
![交易状态图](/img/%5B摘要%5D数据库系统概念/交易状态图.png)&#13;
&#13;
### 并发执行&#13;
&#13;
Concurrent Executions&#13;
&#13;
系统中允许多个事务同时运行.&#13;
优点在于:&#13;
&#13;
- **处理器和磁盘利用率高**, 带来了更高的交易吞吐量&#13;
- 交易的平均响应时间缩短: 短交易无须等待长交易&#13;
&#13;
并发控制方案(实现隔离的机制)&#13;
&#13;
- 要控制并发事务之间的交互, 以防止它们破坏数据库的一致性&#13;
&#13;
调度: 一系列指令，指定了并发事务的指令以何种时间顺序执行.&#13;
&#13;
- 一组事务的调度必须包含这些事务的所有指令。</description><guid isPermaLink="true">https://CX9898.github.io/post/shu-ju-ku-xi-tong-gai-nian.html</guid><pubDate>Tue, 12 Nov 2024 08:01:24 +0000</pubDate></item><item><title>用 CMake 构建跨平台 CUDA C/C++ 项目</title><link>https://CX9898.github.io/post/yong-%20CMake%20-gou-jian-kua-ping-tai-%20CUDA%20C-C%2B%2B%20-xiang-mu.html</link><description>![封面](/img/用_CMake_构建跨平台_CUDA_C_C++项目/封面.png)&#13;
&#13;
# 用 CMake 构建跨平台 CUDA C/C++ 项目&#13;
&#13;
***&#13;
&#13;
## 前言&#13;
&#13;
NVIDIA 官方 [cuda-samples](https://github.com/NVIDIA/cuda-samples) 项目和一些论文的源码中都使用的是 Make 构建, 导致每换一台主机都得重新设置, 太麻烦了. 所以写一遍 CMake 方便构建, 同时顺便记录一下要点.  &#13;
&#13;
本文先解释了为什么要使用 CMake 来构建 CUDA C/C++ 项目. 创建一个项目框架, 一步一步讲解如何手动使用 CMake 构建一个 CUDA C/C++ 项目, 并指出构建 CUDA 项目额外需要的步骤.&#13;
&#13;
文章链接 : [用 CMake 构建跨平台 CUDA C/C++ 项目](https://zhuanlan.zhihu.com/p/701581020)&#13;
&#13;
***&#13;
&#13;
## 为什么使用 CMake&#13;
&#13;
编译CUDA代码可以使用 `nvcc` 工具直接在命令行输入命令进行编译.&#13;
&#13;
```shell&#13;
$ nvcc main.cu -o main&#13;
```&#13;
&#13;
但编译多个文件的时候就需要给每个文件都只编译源码, 最后再一起生成可执行文件.&#13;
&#13;
```shell&#13;
$ nvcc -c kernel.cu -o kernel.o&#13;
$ nvcc -c main.cu -o main.o&#13;
$ nacc kernel.o main.o -o main&#13;
```&#13;
&#13;
实际工程中, 文件数量会非常非常多, 一个个手动调用 `nvcc` 编译链接会变得非常麻烦.&#13;
&#13;
使用 g++ 编译 C++ 项目时同样有这个问题. 为了实现自动编译, 发明了 Make 这个程序. 要使用 Make, 需要创建 Makefile 文件并在文件中写出不同文件之间的依赖关系和生成各文件的规则, 然后只需要输入一个 `make` 命令就能完成构建.&#13;
&#13;
然而 Make 在 Unix 类系统上是通用的, 但是在 Windows 则并不是. 并且Make工具也有分好几种, 例如 GNU Make, QT 的 qmake, 微软的 MS nmake 等等. 这些 Make 工具遵循着不同的规范和标准, 所执行的 Makefile 格式也千差万别. 如果软件想跨平台, 则必须要保证能够在不同平台编译, 要使用上面的 Make 工具自动完成构建, 就得为每一种标准都分别写一次 Makefile 文件.&#13;
&#13;
为了解决以上这个问题, 就有了跨平台的CMake.&#13;
&#13;
![Cross-platform Make](/img/用_CMake_构建跨平台_CUDA_C_C++项目/cross-platform Make.png)&#13;
&#13;
CMake 是一个跨平台的自动化构建系统, 用来管理软件构建的程序, 并不依赖于某特定编译器. CMake 并不直接建构出最终的软件, 而是产生标准的建构档(如 Unix 的 Makefile 或 Windows 的 Visual C++ 的 projects/workspaces), 然后再依一般的建构方式使用.&#13;
&#13;
**CMake 相当于对 Make 进行了封装. 让开发者可以只编写一次构建脚本就能在不同的平台上构建软件, 从而实现'Write once, run everywhere'. 使用统一的格式编写配置文件(CMakeLists.txt), 就能够在不同环境和平台上生成所需的本地化 Makefile 和工程文件.**&#13;
&#13;
**CUDA 也加入了 CMake 支持的各种语言, 平台, 编译器和 IDE.**&#13;
&#13;
&gt; CMake 广泛用于 C 和 C++ 语言，但它也可用于构建其他语言的源代码.&#13;
&#13;
***&#13;
&#13;
## 安装工具&#13;
&#13;
要使用 CUDA, 当然首要至少要有一个 NVIDIA 的 GPU 设备. 然后安装以下工具 :&#13;
- CUDA Toolkit : [Download CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit)&#13;
- CMake : Linux(Ubuntu) 系统可以通过命令 `sudo apt install cmake` 安装. 推荐去官网下载新版本后安装 [Download CMake](https://cmake.org/download/)&#13;
- C/C++ 编译器 : Linux 使用 gcc/g++. Window 推荐使用 [visual studio](https://visualstudio.microsoft.com/zh-hans/)&#13;
&#13;
***&#13;
&#13;
## 环境设置&#13;
&#13;
*Linux(Ubuntu):*&#13;
&#13;
找到设备中 CUDA 安装目录 (默认安装在 `/usr/local/` ).  根据本机的 CUDA 安装路径, 在 `.bashrc` 文件中手动添加 CUDA 库文件到环境变量 `PATH` .&#13;
&#13;
```shell&#13;
export PATH=/usr/local/cuda-12/bin/:$PATH&#13;
export LD_LIBRARY_PATH=/usr/local/cuda-12/lib64:$LD_LIBRARY_PATH&#13;
```&#13;
&#13;
当然保存后还需要加载一次配置&#13;
&#13;
```shell&#13;
$ source ~/.bashrc&#13;
```&#13;
&#13;
*window:*&#13;
&#13;
安装 CUDA Toolkit 后检查有没有将CUDA库目录添加到环境变量Path. 如果没有则需要手动添加.&#13;
&#13;
&gt; 设置-&gt;系统-&gt;关于-&gt;高级系统设置-&gt;环境变量-&gt;系统变量-&gt;Path-&gt;编辑-&gt;新建&#13;
&#13;
```&#13;
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.5\lib&#13;
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.5\libnvvp&#13;
```&#13;
&#13;
***&#13;
&#13;
## 构建项目框架&#13;
&#13;
创建 include 文件夹用来包含项目头文件, 创建 src 文件夹来包含项目源文件, 创建 CMake 配置文件: `CMakeLists.txt` .&#13;
&#13;
```&#13;
.&#13;
├─include&#13;
│  ├─&#13;
├─src&#13;
│  ├─&#13;
└─CMakeLists.txt&#13;
```&#13;
&#13;
&gt; 要编译其他项目只需要将项目源文件复制到 src 文件夹, 头文件复制到 include 文件夹, 并稍作修改 CMakeLists.txt 文件就行.&#13;
&#13;
***&#13;
&#13;
## CMakeLists.txt&#13;
&#13;
使用 CMake 构建一个最简单的项目只需要在配置文件(CMakeLists.txt)中包含三个基本命令:&#13;
- `cmake_minimum_required()` : 指定 CMake 最低版本号&#13;
- `project()` : 创建项目&#13;
- `add_executable()` : 使用指定的源代码文件创建可执行文件&#13;
- &#13;
下面一步一步讲解如何在配置文件中构建一个 CUDA C/C++项目, 并指出构建 CUDA 项目额外需要的步骤.&#13;
&#13;
***&#13;
&#13;
### 设置 CMake 版本&#13;
&#13;
**首先使用 `cmake_minimum_required()` 指定使用的 CMake 最低版本号.**&#13;
&#13;
```cmake&#13;
cmake_minimum_required(VERSION 3.26)&#13;
```&#13;
&#13;
3.26 版本是一个较新的稳定版本.&#13;
&#13;
如果使用的 CMake 版本低于指定的最低版本号, 构建过程可能会失败或不兼容. &#13;
&#13;
&gt;CMake 从3.11版本开始支持 CUDA.&#13;
&#13;
***&#13;
&#13;
### 创建项目&#13;
&#13;
**使用 `project()` 创建项目. 括号里填写项目名.**&#13;
&#13;
```cmake&#13;
project(cmake-cuda-demo)&#13;
```&#13;
项目名将存储在变量 `PROJECT_NAME` 中.&#13;
&#13;
***&#13;
&#13;
### 启用语言支持&#13;
&#13;
**`enable_language()` 用以添加构建项目使用的语言.**&#13;
&#13;
```cmake&#13;
enable_language(CXX)&#13;
enable_language(CUDA)&#13;
```&#13;
&#13;
&gt; 也可以简化在 project() 项目名后添加, 例如: project(cmake-cuda-demo CUDA CXX).&#13;
&#13;
***&#13;
&#13;
### 查找 CUDA 工具包&#13;
&#13;
**`find_package()` 用于添加外部库或软件包**, 如果有不同版本的软件包也可以指定版本号.&#13;
- `REQUIRED` : 如果指定的包找不到, CMake 将报错并停止进一步的配置过程&#13;
- `QUIET` : 安静模式. 即使找不到包, CMake 也不会在控制台输出任何警告或错误信息&#13;
- `EXACT` : 查找的包必须完全匹配指定的版本&#13;
&#13;
使用 CUDAToolkit 来查找 CUDA 工具包.&#13;
&#13;
```cmake&#13;
find_package(CUDAToolkit)&#13;
```&#13;
&#13;
该命令会导入一个名为 `CUDA::toolkit` 的模块, 并且会给包含在 CUDAToolkit 的一些库定义可选的导入目标. 例如使用 `CUDA::cudart` 来导入 CUDA Runtime 库, 使用 `CUDA::cublas` 来导入 cuBLAS 库等. 在下文链接 CUDA 库文件时会详细介绍.&#13;
&#13;
&gt;CMake 旧版本中会使用 `find_package(CUDA)` 来查找 CUDA 工具包, 该命令会查找软件包路径并定义一些内置变量, 但在 CMake 3.10 版本后弃用. 在 CMake 3.17 版本后推荐使用 `find_package(CUDAToolkit)` , 能以更便利的方式添加库文件.&#13;
&#13;
&gt; 关于 FindCUDAToolkit 的详细信息可参考 CMake 官方文档 : [FindCUDAToolkit - CMake 3.30.0 Documentation](https://cmake.org/cmake/help/latest/module/FindCUDAToolkit.html).&#13;
&#13;
***&#13;
&#13;
### 设置 C++ 标准&#13;
&#13;
**要使用 C++ 的一些新特性则需要指定 C++ 标准.**&#13;
&#13;
**`set()` 用于定义/修改变量值.**&#13;
&#13;
**通过修改 CMake 内置变量 `CMAKE_CXX_STANDARD` 来设置项目中 C++ 源文件(.cpp等)使用的 C++ 标准, 通过修改变量 `CMAKE_CUDA_STANDARD` 来设置 CUDA 源文件(.cu)使用的 C++ 标准.** 这是因为源文件可能由不同的编译器处理, CUDA 源文件用 nvcc 编译, 而 C++ 源文件可能会用 g++ 等工具编译.&#13;
&#13;
```cmake&#13;
set(CMAKE_CXX_STANDARD 11)&#13;
set(CMAKE_CUDA_STANDARD 11)&#13;
```&#13;
&#13;
&gt; 通过设置变量 `CMAKE_CXX_STANDARD_REQUIRED` 为 `ON` 可以强制使用指定的 C++ 标准. 如果编译器不支持指定的 C++ 标准, CMake 构建过程将报错.&#13;
&#13;
***&#13;
&#13;
### 选择 CUDA 架构&#13;
&#13;
**变量 `CMAKE_CUDA_ARCHITECTURES` 是 CMake 3.18 版本中加入的一个变量, 用于指定编译 CUDA 代码时支持的 GPU 架构, 如果要使用新架构的一些特性, 则必须要指定特定的架构.**&#13;
&#13;
例如要使用Volta架构开始引入的Tensor core, 则需要指定70及以上架构.&#13;
&#13;
```cmake&#13;
set(CMAKE_CUDA_ARCHITECTURES 70)&#13;
```&#13;
&#13;
&gt;通过NVIDIA驱动的 `nvidia-smi` 命令能查看GPU信息, 或直接输入 `nvidia-smi -q | grep Architecture` 查看架构信息. 具体架构和对应的参数可以参考下表 :&#13;
&#13;
![GPU架构和对应的参数列表](/img/用_CMake_构建跨平台_CUDA_C_C++项目/GPU虚拟架构功能列表.png)&#13;
GPU架构和对应的参数列表&#13;
&#13;
***&#13;
&#13;
### 用变量存储文件夹路径&#13;
&#13;
**添加创建的 include 文件夹路径储存到变量 `INCLUDE_DIR` , 添加 src 文件夹路径储存到变量 `SRC_DIR` .**&#13;
&#13;
```cmake&#13;
set(INCLUDE_DIR '${CMAKE_SOURCE_DIR}/include')&#13;
set(SRC_DIR '${CMAKE_SOURCE_DIR}/src')&#13;
```&#13;
&#13;
&gt; 变量 `CMAKE_SOURCE_DIR` 是 CMake 的内置变量, 储存最外层 CMakeLists.txt 文件所在的目录. 如果项目有多个子目录和子 CMakeLists.txt 文件, `CMAKE_SOURCE_DIR` 始终指向最外层的路径. `CMAKE_BINARY_DIR` 则对应子 CMakeLists.txt 文件的路径.&#13;
&#13;
***&#13;
&#13;
### 生成文件列表&#13;
&#13;
**使用 `file(GLOB)` 可以根据指定的模式匹配文件名，并将匹配到的文件列表赋值给一个变量.**&#13;
&#13;
读取 src 文件夹的 CUDA, C,  C++源文件储存在变量 `SRC_FILES` 中.&#13;
&#13;
```cmake&#13;
file(GLOB SRC_FILES '${SRC_DIR}/*.c' '${SRC_DIR}/*.cpp' '${SRC_DIR}/*.cc' '${SRC_DIR}/*.cxx' '${SRC_DIR}/*.cu')&#13;
```&#13;
&#13;
&gt; 使用 file(GLOB_RECURSE) 可以递归搜索目录及其所有子目录中的文件&#13;
&#13;
***&#13;
&#13;
#打印信息&#13;
**`message()` 用于在 CMake 的构建过程中输出信息, 可以使用它来打印出变量的值, 或检查调试信息.**&#13;
&#13;
可以用于检查上个命令中变量 `SRC_FILES` 是否包含了目标源文件.&#13;
&#13;
```cmake&#13;
message(STATUS 'Src files: ${SRC_FILES}')&#13;
```&#13;
&#13;
- `STATUS` : 显示一般状态信息&#13;
- `WARNING` : 显示警告信息&#13;
- `FATAL_ERROR` : 显示错误信息并停止 CMake 进程&#13;
- `SEND_ERROR` : 显示错误信息但继续 CMake 进程&#13;
&#13;
还可以配合条件语句来检查 CUDA 是否被正确添加.&#13;
&#13;
```cmake&#13;
if (CMAKE_CUDA_COMPILER)&#13;
message(STATUS 'nvcc path : ${CMAKE_CUDA_COMPILER}')&#13;
else ()&#13;
message(WARNING 'nvcc not found. Please check CUDA is installed correctly!')&#13;
endif ()&#13;
```&#13;
&#13;
&gt; 当然了, 如果没有正确添加, 在 `enable_language(CUDA)` 就会报错, 这里只是给出示例&#13;
&#13;
***&#13;
&#13;
### 添加构建目标&#13;
&#13;
**`add_executable()` 用以向项目中添加要从源代码构建的可执行目标.**&#13;
&#13;
```cmake&#13;
add_executable(${PROJECT_NAME} ${SRC_FILES})&#13;
```&#13;
一个配置文件中可以使用 `add_executable()` 添加多个目标.&#13;
&#13;
***&#13;
&#13;
### 添加头文件目录&#13;
&#13;
**使用 `target_include_directories()` 可以为目标项目添加头文件目录, 使编译器可以找到目标所依赖的头文件.**&#13;
&#13;
使用前面定义好的 `INCLUDE_DIR` 变量来添加 include 头文件目录.&#13;
&#13;
```cmake&#13;
target_include_directories(${PROJECT_NAME} PRIVATE ${CUDA_INCLUDE_DIRS})&#13;
target_include_directories(${PROJECT_NAME} PRIVATE ${INCLUDE_DIR})&#13;
```&#13;
&#13;
- `PRIVATE` ：链接的库仅对目标自身可见&#13;
- `PUBLIC` ：链接的库对目标自身和链接到该目标的所有其他目标都可见&#13;
- `INTERFACE` ：链接的库仅对链接到该目标的其他目标可见&#13;
&#13;
&gt; 全局添加使用 `include_directories()` 命令. 当有多个目标需要构建, 并且需要包含相同的头文件路径时, 全局添加可以减少重复的代码. 但在大多数情况下推荐使用局部添加, 能使项目的依赖关系更加明确.&#13;
&#13;
***&#13;
&#13;
### 链接 CUDA 库文件&#13;
&#13;
**使用 `target_link_libraries()` 指定目标项目在链接时需要使用的库文件.**&#13;
&#13;
CUDA Runtime, cuBLAS 和 cuSPARSE 等库包含在 [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit) 包中. 如果要使用它们, 只需要链接对应的库文件.&#13;
&#13;
例如使用储存了 CUDA Runtime 库文件的变量 CUDA_cudart_LIBRARY 来链接 CUDA Runtime 库文件.&#13;
&#13;
```cmake&#13;
target_link_libraries(${PROJECT_NAME} PRIVATE ${CUDA_cudart_LIBRARY})&#13;
```&#13;
&#13;
也可以直接使用 CMake 中 [FindCUDAToolkit](https://cmake.org/cmake/help/latest/module/FindCUDAToolkit.html#cuda-toolkit-rt-lib) 模块定义好的目标来导入.&#13;
&#13;
```cmake&#13;
# Linked cuda Runtime library&#13;
target_link_libraries(${PROJECT_NAME} PRIVATE CUDA::cudart)&#13;
&#13;
# Linked cuBLAS library&#13;
target_link_libraries(${PROJECT_NAME} PRIVATE CUDA::cublas)&#13;
&#13;
# Linked cuFFT library&#13;
target_link_libraries(${PROJECT_NAME} PRIVATE CUDA::cufft)&#13;
&#13;
# Linked cuRAND library&#13;
target_link_libraries(${PROJECT_NAME} PRIVATE CUDA::curand)&#13;
&#13;
# Linked cuSOLVER library&#13;
target_link_libraries(${PROJECT_NAME} PRIVATE CUDA::cusolver)&#13;
&#13;
# Linked cuSPARSE library&#13;
target_link_libraries(${PROJECT_NAME} PRIVATE CUDA::cusparse)&#13;
```&#13;
&#13;
并且使用模块定义好的目标来导入库文件的同时也会自动添加相关的头文件, 使 C++ 源文件中也可以调用.&#13;
&#13;
&gt; 如果要使用cuDNN库, 则需要去官网下载 cuDNN: [Downloads cuDNN](https://developer.nvidia.com/cudnn-downloads), 设置好环境, 然后查找 cuDNN 包并添加头文件目录和库文件.&#13;
&#13;
以上源码可在 GitHub 上获取 : [GitHub - CX9898/cmake-cuda-sample](https://github.com/CX9898/cmake-cuda-sample)&#13;
&#13;
***&#13;
&#13;
## 构建&#13;
&#13;
目前很多IDE都支持 CMake, 可以实现一键构建, 比如我现在用的 CLion. 但是有时候还是需要手动构建, 这里用来记录一下.&#13;
&#13;
***&#13;
&#13;
### Linux(Ubuntu)&#13;
&#13;
在项目文件夹中创建并进入 `build` 文件夹, 然后运行 `CMake ..` 和 `make` :&#13;
&#13;
```shell&#13;
$ mkdir build&#13;
$ cd build&#13;
$ cmake ..&#13;
$ make&#13;
```&#13;
&#13;
最终在 build 文件夹中就会生成可执行文件:&#13;
&#13;
![](/img/用_CMake_构建跨平台_CUDA_C_C++项目/Linux构建结果.png)&#13;
&#13;
&gt; 也可以直接使用 `cmake --build build` 来创建 build 文件夹并开始构建.&#13;
&#13;
***&#13;
&#13;
### window&#13;
&#13;
首先选择 CMakeLists.txt 文件所在的路径.&#13;
&#13;
![](/img/用_CMake_构建跨平台_CUDA_C_C++项目/Window使用CMake选择项目源目录.png)&#13;
&#13;
选择构建的位置. 选择在项目目录中创建的 build 文件夹.&#13;
&#13;
![](/img/用_CMake_构建跨平台_CUDA_C_C++项目/Window使用CMake选择构建的位置.png)&#13;
&#13;
选择完后点击 `Configure` 按钮进入编译器选项.&#13;
&#13;
![](/img/用_CMake_构建跨平台_CUDA_C_C++项目/Window使用CMake选择configure.png)&#13;
&#13;
选择编译器, 推荐使用 [visual studio](https://visualstudio.microsoft.com/zh-hans/). 然后点击 `Finish` .&#13;
&#13;
![](/img/用_CMake_构建跨平台_CUDA_C_C++项目/Window使用CMake选择编译器.png)&#13;
&#13;
可以在变量 `CMAKE_INSTALL_PREFIX` 中设置要安装的路径, 然后点击 `Generate` 开始构建.&#13;
&#13;
![](/img/用_CMake_构建跨平台_CUDA_C_C++项目/Window使用CMake构建页面.png)&#13;
&#13;
构建成功后, 旁边的 `Open Project` 按钮也亮了, 点击 `Open Project` 进入编译器开始编译.&#13;
&#13;
右边的解决方案资源管理器中选择 `ALL_BUILD` , 右键选择 `生成` .&#13;
&#13;
![](/img/用_CMake_构建跨平台_CUDA_C_C++项目/Window VS解决方案资源管理器.png)&#13;
&#13;
`ALL_BUILD` 完成后, 项目目录的 build 文件夹中的 Debug 目录里就已经生成可执行文件了.&#13;
&#13;
![](/img/用_CMake_构建跨平台_CUDA_C_C++项目/Window构建结果.png)&#13;
&#13;
要编译 Release 版本只需要构建前在变量 `CMAKE_CONFIGURATION_TYPES` 中设置为 `Release` 即可.&#13;
&#13;
在解决方案资源管理器中选择 `INSTALL` , 右键选择 `生成` , 就可以将可执行文件安装到指定目录.&#13;
&#13;
***&#13;
&#13;
## 扩展&#13;
&#13;
### OpenMP&#13;
&#13;
**OpenMP(Open Multi-Processing) 是一个并行API，用于在C/C++程序中方便地实现多线程编程.** 如果要加入OpenMP库, 则需要先找到 OpenMP 包再添加 OpenMP 库文件.&#13;
&#13;
```cmake&#13;
# Find OpenMP package&#13;
find_package(OpenMP REQUIRED)&#13;
&#13;
# Linked OpenMP library&#13;
target_link_libraries(${PROJECT_NAME} PRIVATE OpenMP::OpenMP_CXX)&#13;
```&#13;
&#13;
&gt; 注意 : OpenMP 主要用于在 Host 端并行化 CPU 代码, 需要在 C++ 源文件中使用.&#13;
&#13;
**添加其他第三方库(例如 Boost, HDF5)时一般也是按照先用 `find_package()` 找到对应软件包, 再用 `target_include_directories()` 和  `target_link_libraries()` 添加对应的头文件和库文件.**&#13;
&#13;
***&#13;
&#13;
### 安装设置&#13;
&#13;
**CMake 也可以指定安装规则. 当使用 cmake 产生 Makefile 后, 还可以通过执行make install命令来将编译生成的可执行文件, 库文件, 头文件等安装到指定位置.**&#13;
&#13;
**使用 `install()` 来设置安装规则.** 通过设置变量 `CMAKE_INSTALL_PREFIX` 可以指定安装路径. 如果不指定路径则默认安装到 `/usr/local`.&#13;
&#13;
```cmake&#13;
set(CMAKE_INSTALL_PREFIX '${CMAKE_SOURCE_DIR}')&#13;
&#13;
install(TARGETS ${PROJECT_NAME} DESTINATION bin)&#13;
```&#13;
&#13;
- `TARGETS` 用于指定需要安装的目标, 可以一次指定多个目标, 使用分号 `;` 分隔&#13;
- 根据目标类型, 可以使用 `RUNTIME`, `LIBRARY` , `ARCHIVE` 等关键字来指定不同类型的文件的安装规则&#13;
- `DESTINATION` 用于指定安装的目的地. 例如 `DESTINATION bin` 表示在安装路径中创建 bin 文件夹, 将目标文件安装到 bin 文件夹中&#13;
&#13;
&gt; DESTINATION也可以不使用默认的安装路径, 直接使用固定参数.&#13;
例如: `DESTINATION '${CMAKE_SOURCE_DIR}/bin'`&#13;
&#13;
***&#13;
&#13;
参考：&#13;
&#13;
[cmake-commands(7) - CMake 3.30.0 Documentation](https://cmake.org/cmake/help/latest/manual/cmake-commands.7.html)&#13;
&#13;
[FindCUDAToolkit - CMake 3.30.0 Documentation](https://cmake.org/cmake/help/latest/module/FindCUDAToolkit.html)&#13;
&#13;
[Linux嵌入式：全网最细的CMake教程！(强烈建议收藏)](https://zhuanlan.zhihu.com/p/534439206)&#13;
&#13;
[佳佳：学C++从CMake学起](https://zhuanlan.zhihu.com/p/657235610)&#13;
&#13;
[使用 CMake 构建跨平台 CUDA 应用程序](https://developer.nvidia.com/zh-cn/blog/building-cuda-applications-cmake/)&#13;
。</description><guid isPermaLink="true">https://CX9898.github.io/post/yong-%20CMake%20-gou-jian-kua-ping-tai-%20CUDA%20C-C%2B%2B%20-xiang-mu.html</guid><pubDate>Wed, 10 Jul 2024 08:28:53 +0000</pubDate></item><item><title>基于行分解的GPU稀疏矩阵乘法</title><link>https://CX9898.github.io/post/ji-yu-xing-fen-jie-de-GPU-xi-shu-ju-zhen-cheng-fa.html</link><description>![论文封面](/img/[论文笔记]基于行分解的GPU稀疏矩阵乘法/论文封面.png)&#13;
&#13;
# [论文笔记]基于行分解的GPU稀疏矩阵乘法&#13;
&#13;
**A Row Decomposition-based Approach for Sparse Matrix Multiplication on GPUs**&#13;
&#13;
论文于2024年发表在PPoPP '24: Proceedings of the 29th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming.&#13;
&#13;
稀疏矩阵稠密矩阵乘法(SpMM)和采样稠密-稠密矩阵乘法(SDDMM)是各种计算领域中重要的稀疏核. 论文提出了一种**基于行分解(RoDe)的方法来优化GPU上的两个内核**.使用了标准的压缩稀疏行(CSR)格式. 具体来说,**RoDe将稀疏矩阵行划分为规则部分和残差部分, 分别充分优化它们的计算.还设计了相应的负载均衡和细粒度流水线技术**.与最先进的替代方案相比, Rode的SpMM内核最高达到7.86倍加速, SDDMM内核最高达到8.99倍加速.&#13;
&#13;
文章链接[[论文笔记]基于行分解的GPU稀疏矩阵乘法](https://zhuanlan.zhihu.com/p/703369002)&#13;
&#13;
***&#13;
&#13;
## 图形处理器(GPU)&#13;
&#13;
物理上, **GPU是由一组流式多处理器(SMs)组成. GPU内核中, 线程(threads)被分成很多个线程块(thread blocks), 在每个线程块(thread blocks)内连续的32个线程组成一组, 称为线程束(warp)**.&#13;
&#13;
&gt; 线程束(warp)是SM中的最小执行单位. 在一个线程束中, 所有线程按照单指令多线程(SIMT)的方式执行, 也就是32个线程在同时同步执行，线程束中的每个线程执行同一条指令，包括有分支的部分, 但是处理的数据为私有的数据. 如果一个 warp 内的线程产生分支,该 warp 将执行每一个分支路径, 同时禁用不在该路径上的线程.&#13;
&#13;
![从逻辑角度和硬件角度描述了CUDA编程模型对应的组件. 图片来自谭升的博客](/img/[论文笔记]基于行分解的GPU稀疏矩阵乘法/从逻辑角度和硬件角度描述了CUDA编程模型对应的组件.图片来自谭升的博客.png)&#13;
&#13;
从逻辑角度和硬件角度描述了CUDA编程模型对应的组件. 图片来自谭升的博客.&#13;
&#13;
当内核在GPU上开始执行时, 线程块以最大化并行性和最小化资源冲突的方式分配给可用的SMs. 在每个SM中, GPU调度器进一步将分配的线程块划分为warp. 每个warp由warp调度器(warp scheduler) 安排执行, 一旦选择执行某个warp, SM的指令调度程序接收这个 warp 的指令, 并将其分配给SM中的执行单元, 以便执行这些指令. GPU可以通过在SM内调度warp来隐藏指令的延迟.&#13;
&#13;
&gt; 每个SM上有非常多的执行单元. 如果某个warp中的线程需要等待数据或发生分支时, warp调度器可以选择其他准备好执行的warp来执行. 利用其他warp的执行来保持执行单元的忙碌状态, 有效地隐藏了指令延迟, 提高GPU的利用率.&#13;
&#13;
GPU有一个大但是高延迟的全局内存, 所有SMs都可以访问它. 一个L2缓存由所有SMs共享, L1缓存位于每个SM的本地.  一个线程块内的所有线程都可以访问同一块共享内存, 并且每个线程都有本地寄存器.&#13;
&#13;
&gt; 同一个线程块内的线程除了都可以访问同一块共享内存外, 在同一个线程束中的线程还可以通过 shuffle 指令进行通信. 通过 suffle 指令, 两个线程间可以相互访问对方的寄存器, 并且延迟极低, 不消耗内存.&#13;
&#13;
当一个warp中的多个线程访问连续的全局内存位置时, GPU可以将这些访问合并到一个事务中, 以提高效率.  每个线程还可以使用单个向量内存指令加载多个数据(例如, 一次加载4个浮点数)&#13;
&#13;
***&#13;
&#13;
## Sparse-Matrix Dense-Matrix Multiplication&#13;
&#13;
稀疏-稠密矩阵乘法(SpMM)是线性代数中的常见操作, 在科学计算, 机器学习等领域有着广泛的应用.&#13;
&#13;
**稀疏矩阵在存储上通常使用特殊的数据结构来优化内存使用和计算效率**，因为它们包含大量的零元素. 例如, 压缩稀疏行(Compressed Sparse Row, CSR), 压缩稀疏列(Compressed Sparse Column, CSC), 坐标列表(Coordinate List, COO)等. **论文中采用按行压缩的CSR表示**, 这是稀疏矩阵中使用最广泛的数据结构之一.&#13;
&#13;
![稀疏矩阵和对应的CSR表示](/img/[论文笔记]基于行分解的GPU稀疏矩阵乘法/稀疏矩阵和对应的CSR表示.png)&#13;
&#13;
稀疏矩阵和对应的CSR表示.&#13;
&#13;
矩阵只储存非零元素, 行指针数组`row_ptr`中的每个元素指向值数组中对应行的第一个非零元素的位置，列索引数组`col_idx`存储了非零元素的列位置，而值数组`values`则存储了所有非零元素的数值.&#13;
&#13;
&gt; 例如, 取第4行的所有元素, 并获取对应列号:&#13;
&#13;
```C++&#13;
int row = 4;&#13;
for(int idx = row_ptr[row]; idx &lt; row_ptr[row + 1]; ++idx){ // idx : 7, 8&#13;
    const auto val = values[idx]; // val : h, i&#13;
    const int col = col_idx[idx]; // col : 2, 4&#13;
}&#13;
```&#13;
&#13;
***&#13;
&#13;
## Sampled Dense-Dense Matrix Multiplication&#13;
&#13;
采样稠密-稠密矩阵乘法(SDDMM)具有一个稀疏矩阵和两个稠密矩阵作为输入,一个稀疏矩阵作为输出. 采样指的是对两个稠密矩阵乘法的结果矩阵中随机保留一些元素. **SDDMM计算两个稠密输入矩阵的乘积, 但仅根据输入稀疏矩阵对应的非零位置处进行计算, 并与对应位置的非零权重值相乘**.&#13;
&#13;
&gt; 关于SDDMM具体介绍可以参考另一篇笔记: [CX98：[论文笔记]用于高性能机器学习的抽样稠密矩阵乘法](https://zhuanlan.zhihu.com/p/699010780)&#13;
&#13;
***&#13;
&#13;
## 分析非零分布&#13;
分析来自 SuiteSparse 集合的稀疏矩阵的每一行中的非零分布.&#13;
&gt; SuiteSparse 是一个大型的稀疏矩阵集合, 它包含了许多实际应用中的稀疏矩阵.&#13;
&#13;
![左图显示每个矩阵的平均行长(每行非零元素的数量). 中间图绘制了每个特定行的长度分布. 右图显示每个矩阵内的行数分布. 数据集来自SuiteSparse](/img/[论文笔记]基于行分解的GPU稀疏矩阵乘法/数据集SuiteSparse.png)&#13;
&#13;
左图显示每个矩阵的平均行长(每行非零元素的数量). 中间图绘制了每个特定行的长度分布. 右图显示每个矩阵内的行数分布. 数据集来自SuiteSparse.&#13;
&#13;
得出**数据集中稀疏矩阵的三个属性:**&#13;
- **大多数矩阵的平均行长都小于32(红线)**&#13;
- **大部分行都很短(84%的行长度小于32), 但也有一些行长度达到几千甚至上万**&#13;
- **很多矩阵主要由短行组成, 包含少量的长行**&#13;
&#13;
属性①导致难以充分利用GPU的计算或内存访问资源, 减少了一些可优化的空间.&#13;
&#13;
&gt; 上面提到SM的最小执行单位是线程束(warp), 一个warp由32个线程组成, 32个线程同时同步执行指令. 按照一个线程计算一个非零元素, 一行中的非零元素少于32个导致有很多线程处于空闲状态.&#13;
&#13;
属性②表示对长行进行优化是有益的. 可以用向量内存指令和更多的线程来优化这些行.&#13;
&#13;
&gt; Vector Memory Instructions(向量内存指令)是GPU编程中的一种技术, 它允许单个线程使用一条指令从内存中加载多个数据元素(例如一次性加载4个浮点数). 这种技术可以提高内存访问的效率，因为它减少了访问内存的次数, 同时利用了GPU的SIMD(单指令多数据)特性.&#13;
&#13;
属性③指出, 对于很多矩阵, 属性①和属性②是共存的. 意味着应该在一次计算中同时优化它们. 并且长短行的数量差距很大, 需要积极的负载均衡.&#13;
&#13;
**结论: 需要同时优化长,短行, 避免优化不彻底, 同时负载均衡也很重要.**&#13;
&#13;
***&#13;
&#13;
## 分析计算管道&#13;
&#13;
GPU上进行矩阵求解时, 通常利用分块(tiling)技术, 将稀疏矩阵和稠密矩阵划分为多个块(tile), 每个块(tile)只包含矩阵的一部分行和列. 随后迭代计算每个块, 并将其结果累加到结果块中.&#13;
&#13;
&gt; 分块(tiling): 指的是将大数据集(如矩阵)划分为较小的块(tile)(或称为瓦片). 这些小块的大小通常与GPU的共享内存大小相匹配，以便可以完全加载到共享内存中. 是常用的优化技术.&#13;
&#13;
![常见的稀疏稠密矩阵乘法计算流水线](/img/[论文笔记]基于行分解的GPU稀疏矩阵乘法/常见的稀疏稠密矩阵乘法计算流水线.png)&#13;
&#13;
常见的稀疏稠密矩阵乘法计算流水线.&#13;
&#13;
如图所示GPU上稀疏稠密矩阵乘法主要分为三个阶段: 加载稀疏块, 加载稠密块和计算.&#13;
&#13;
由于要利用稀疏块内的列索引来加载稠密块, 最终的计算则需要完成对稠密块的加载, 这三个阶段表现出紧密的数据依赖关系. 为了使稀疏块在线程之间重用, 一般将其放在共享内存中, 由不同的线程加载稀疏块的不同部分, 这就需要线程间的同步操作`syncthreads`.&#13;
&#13;
但上述**同步限制了编译器的优化空间, 并且稠密块中更大的数据量使得在加载稠密块时, 管道经常会出现停顿**. 通过 Nvidia Nsight Compute 分析得出, warp 需要花费几倍的时间周期的延迟在等待稠密块数据的计算指令上. **如果能在内存访问的延迟内执行更多的指令或更多的计算, 对这部分会有很好的提速效果**.&#13;
&#13;
&gt; Warp准备好执行下一条指令所需的时钟周期称为延迟, warp 调度器可以在这些延迟周期内, 向其他 warp 发出指令, 从而实现资源的充分利用, 这种方法被称为延迟隐藏.&#13;
&#13;
***&#13;
&#13;
## RoDe&#13;
&#13;
行分解(RoDe)方法旨在使用CSR表示法在GPU上加速稀疏矩阵乘法. 主要分为三个部分: 行分解(Row Decomposition), 块分割(Block  Split)和子块流水线(Sub-block Pipeline).&#13;
&#13;
![RoDe方法工作流程](/img/[论文笔记]基于行分解的GPU稀疏矩阵乘法/RoDe方法工作流程.png)&#13;
&#13;
RoDe方法工作流程.&#13;
&#13;
**先将稀疏矩阵的行分解(Row Decomposition)为块部分(a)和残差部分(b), 分别进行处理. 将块分割(Block Split)方法应用于块部分以实现负载平衡. 最后构建子块流水线, 在连续的同步之间执行更多的操作, 以更好的隐藏内存访问延迟.**&#13;
&#13;
***&#13;
&#13;
### 行分解(Row Decomposition)&#13;
&#13;
根据分析稀疏矩阵的非零分布得出的属性③, **将长短行分开进行处理**. 但并没有将长短行直接分成两组, 而是**把每行都分成块部分(block part)和残差部分(residual part). 将这两部分分开组合, 独立进行处理**.&#13;
&#13;
![行分解的一个例子](/img/[论文笔记]基于行分解的GPU稀疏矩阵乘法/行分解的一个例子.png)&#13;
&#13;
行分解的一个例子. (a)为块部分(非零元素数量为32的倍数), (b)为残差部分(将一行元素数量与32取余,余数为残差部分). 虚线方框表示在实际实现中不需要储存.&#13;
&#13;
&gt; 例如第二行有104个非零元素, 将元素数量与32取余, 104%32 = 8. 则第二行最后8个非零元素为残差部分, 前96个元素为块部分.&#13;
&#13;
为每个部分使用两个辅助数组来实现行分解:&#13;
- rowIndexes: 将每个部分的行索引储存在稀疏矩阵中.&#13;
- StartOffset: 储存每个部分中每行起始元素的索引.(在实际实现中, 可以在运行时被推算出来).&#13;
&#13;
通过将行分解为块部分和残差部分, 可以分别对属性①和②进行优化. 使用具有较大线程块的内核处理块部分, 使用具有较小线程块的内核处理剩余部分.&#13;
&#13;
&gt; 行分解使得每行的两个部分可以单独处理, 从而提高了GPU资源的利用率.&#13;
&#13;
***&#13;
&#13;
### 块分割(Block  Split)&#13;
&#13;
属性②和③说明单个矩阵中, **不同行的长度差异很大, 需要良好的负载均衡**.&#13;
&#13;
在行分解的基础上引入了块分割(block split)方法. **将块部分的每一行划分为固定长度的分段, 数组`RowIndices`记录每个分段的行索引.`StartOffsets`储存每个分段中第一个元素的起始索引**.&#13;
&#13;
![块分割的例子](/img/[论文笔记]基于行分解的GPU稀疏矩阵乘法/块分割的例子.png)&#13;
&#13;
块分割的例子. `RowIndices`储存行索引, `StartOffsets`储存对应的起始下标.&#13;
&#13;
块分割后, 每行的元素被分割成连续的分段,将每个分段视为一个独立的行进行处理, 并且使用`atoMicAdd`指令将每个段的结果累积到最终输出中.&#13;
&#13;
**每个分段中连续的数据储存有利于GPU上线程的联合内存访问. 并且每个分段都有相同数量的元素, 更容易实现负载均衡**. 生成这两个数组只需要花费很小的预处理操作.&#13;
&#13;
***&#13;
&#13;
### 子块流水线(Sub-block Pipeline)&#13;
&#13;
由于全局内存访问的长延迟, 常见的负载计算流水线可能会收到性能限制. 论文引入了子块流水线方法, 用以更好地重叠共享内存访问, 全局内存访问和计算. 原理是**在内存访问的延迟内, 发出尽可能多的指令和执行尽可能多的计算**.&#13;
&#13;
![子块流水线](/img/[论文笔记]基于行分解的GPU稀疏矩阵乘法/子块流水线.png)&#13;
&#13;
子块流水线. 每个块的左边缘表示指令发出的时间. 例如ld dn[1]在comp[0]之前发出.&#13;
&#13;
为了确保数据重用, 选择将稀疏块加载到共享内存中, 而将密集块直接加载到寄存器中. 各个线程加载一部分稀疏块,并且合并到共享内存中. 由于加载密集块时需要稀疏块的列标, 因此在加载密集块前的同步操作是不可避免的.&#13;
&#13;
对于图中的例子, 将密集块划分为两个子块dn[0]和dn[1], 首先加载dn[0], 然后在加载子块dn[1]的同时计算子块[0]. 在加载稀疏块sp[2]和sp[3]时同时计算子块[1].&#13;
&#13;
**这个方法构建了一个更精细的流水线, 将加载内存和计算交错进行, 有效扩展了指令的重叠空间, 更好的使用计算资源**. 再次通过 Nvidia Nsight Compute 分析, 花费的等待时间周期明显减少.&#13;
&#13;
&gt; 扩展了指令的重叠空间意味着更能利用warp调度器的调度能力, 实现资源的充分利用, 能够更好地隐藏延迟.&#13;
&#13;
***&#13;
&#13;
## RoDe性能测试&#13;
&#13;
- 环境: CUDA 11.2  Nvidia A100-PCIE-40GB GPU. CUDA代码使用带有-O3标志的NVCC 11.1进行编译&#13;
- 数据集: SuiteSparse集合中选择900多个矩阵, 这些矩阵至少有10K行,10K列和100K个非零. 矩阵来自不同的应用领域, 包括科学计算, 图形处理, 图形挖掘等, 并且包含广泛的稀疏模式&#13;
- 比较方法 : 与Nvidia cuSPARSE库, ASpT和Sputnik进行比较. 对内核执行时间和与处理时间分别进行分析. 所有测试都连续运行10次得到平均值&#13;
&#13;
***&#13;
&#13;
### SpMM内核&#13;
&#13;
![SpMM性能结果](/img/[论文笔记]基于行分解的GPU稀疏矩阵乘法/SpMM性能结果.png)&#13;
&#13;
SpMM性能结果. 图中每个点表示连续5个矩阵集的平均GFLOP.&#13;
&#13;
- cuSPARSE基线上的加速：RoDe实现了特定情况下高达32.17倍的加速. 几何平均值为1.91倍.&#13;
- Sputnik基线上的加速：RoDe实现了特定情况下高达198.51倍的加速. 几何平均值为1.83倍.&#13;
- ASpT基线上的加速：RoDe实现了特定情况下高达8.02倍的加速. 几何平均值为1.45倍.&#13;
&#13;
***&#13;
&#13;
### SDDMM内核&#13;
&#13;
![SDDMM性能结果](/img/[论文笔记]基于行分解的GPU稀疏矩阵乘法/SDDMM性能结果.png)&#13;
&#13;
SDDMM性能结果. 图中每个点表示连续5个矩阵集的平均GFLOP.&#13;
&#13;
与ASP相比, FP32(K=32)和FP32(K=128)的两种情况下, RoDe实现了高达8.99倍和8.80倍的加速, 几何平均值分别为1.54倍和1.44倍.&#13;
&#13;
***&#13;
&#13;
## 结语&#13;
&#13;
论文首先分析了稀疏矩阵的跨行分布特性, 总结出将长短行分别进行优化和负载均衡的重要性. 利用行分解技术解耦了块部分和残差部分, 引入了新的负载均衡和更细致的计算流水线技术对稀疏矩阵乘法进行进一步优化.&#13;
&#13;
可能有理解或表述不当的地方, 欢迎大家指正.&#13;
&#13;
论文链接: [A Row Decomposition-based Approach for Sparse Matrix Multiplication on GPUs](https://dl.acm.org/doi/10.1145/3627535.3638470)&#13;
&#13;
&lt;!-- ##{'timestamp':1718603087}## --&gt;。</description><guid isPermaLink="true">https://CX9898.github.io/post/ji-yu-xing-fen-jie-de-GPU-xi-shu-ju-zhen-cheng-fa.html</guid><pubDate>Mon, 17 Jun 2024 05:44:47 +0000</pubDate></item><item><title>用于高性能机器学习的抽样稠密矩阵乘法</title><link>https://CX9898.github.io/post/yong-yu-gao-xing-neng-ji-qi-xue-xi-de-chou-yang-chou-mi-ju-zhen-cheng-fa.html</link><description>![论文封面](/img/[论文笔记]用于高性能机器学习的抽样稠密矩阵乘法/论文封面.png)&#13;
&#13;
# [论文笔记]用于高性能机器学习的抽样稠密矩阵乘法&#13;
&#13;
**Sampled Dense Matrix Multiplication for High-Performance Machine Learning**&#13;
&#13;
论文于 2018 年发表在 IEEE 25th International Conference on High Performance Computing (HiPC).&#13;
&#13;
论文详细介绍了**采样稠密-稠密矩阵乘法(SDDMM)** 作为许多机器学习因子分析算法（如 Alternating Least Squares (ALS)、Latent Dirichlet Allocation (LDA)、Sparse Factor Analysis (SFA) 和 Gamma Poisson (GaP)）的核心组件. **SDDMM 需要计算两个输入稠密矩阵的乘积，但仅在结果矩阵中对应于第三个输入稀疏矩阵的非零位置处进行计算.** 论文还介绍了 cuSDDMM，这是一个多节点 GPU 加速的 SDDMM 实现，相对于当前最佳的 GPU 实现（在 BIDMach 机器学习库中）具有最高4.6倍的加速效果.&#13;
&#13;
文章链接 : [[论文笔记]用于高性能机器学习的抽样稠密矩阵乘法](https://zhuanlan.zhihu.com/p/699010780)&#13;
&#13;
***&#13;
&#13;
## Sampled Dense-Dense Matrix Multiplication&#13;
&#13;
采样稠密-稠密矩阵乘法(SDDMM)具有一个稀疏矩阵和两个稠密矩阵作为输入,一个稀疏矩阵作为输出. 采样指的是对两个稠密矩阵乘法的结果矩阵中随机保留一些元素. **SDDMM计算两个稠密输入矩阵的乘积, 但仅根据输入稀疏矩阵对应的非零位置处进行计算, 并与对应位置的非零权重值相乘.**&#13;
&gt; 在几种ML算法中(如交替最小二乘(ALS)), SDDMM内核在计算上占主导地位(占总执行时间的65%), 优化SDDMM算法可以提高几种ML算法的性能.&#13;
&#13;
![SDDMM示例:在稀疏矩阵S中非零位置的元素累积稠密矩阵A和B的乘积,生成输入稀疏矩阵P](/img/[论文笔记]用于高性能机器学习的抽样稠密矩阵乘法/SDDMM示例_在稀疏矩阵S中非零位置的元素累积稠密矩阵A和B的乘积,生成输入稀疏矩阵P.png)&#13;
&#13;
SDDMM示例:在稀疏矩阵S中非零位置的元素累积稠密矩阵A和B的乘积,生成输入稀疏矩阵P.&#13;
&#13;
&gt; 在矩阵乘法中处理大规模稠密矩阵时, 计算复杂度和内存开销是主要挑战. 采样技术通过选择矩阵中的一部分元素进行计算, 从而有效降低计算量.&#13;
&#13;
SDDMM可以使用A和B之间的高效稠密矩阵乘法(DGEMM)执行,然后提取采样元素. 但是这样会产生大量不必要的计算. **通过只执行与非零元素对应的计算,计算复杂度可以从O(K.M.N)降低到O(K.nnz)(nnz:number of non-zero)**.&#13;
&#13;
与研究较多的优化SpMV(稀疏矩阵向量积)问题相比, SDDMM具有一个输入稀疏矩阵和两个输入稠密矩阵, 因此在**为GPU设计有效并行实现时,需要考虑更多的数据访问**. 而且与内存带宽严重受限的SpMV不同的是, **SDDMM的每个输入稀疏矩阵的元素都会乘以两个稠密输入矩阵的向量的点积, 具有很多可以合并的内存访问**. 因此与SpMV相比, SDDMM显著提高了Roofline性能极限.&#13;
&#13;
&gt; Roofline模型是关注算力和带宽来研究和分析程序运行的瓶颈, 具体可以参考这个文章: [Roofline Model与深度学习模型的性能分析](https://zhuanlan.zhihu.com/p/34204282)&#13;
&#13;
***&#13;
&#13;
## cuSDDMM&#13;
&#13;
论文介绍的cuSDDMM是一种SDDMM的多节点GPU加速实现. 通过分析SDDMM的数据重用特征给出了两种解决方案. SM-SM(Shared memory-Shared memory)方案和SM-L2(shared memory-L2 cache)方案.&#13;
&#13;
&gt; 在GPU加速优化中, 对于数据重用的情况, 利用共享内存来加速是一个很常用方法. 共享内存访问的低延迟和高带宽可以很好地优化数据重用. 对于共享内存的详细介绍可以查看这个博客: [【CUDA 基础】5.1 CUDA共享内存概述](https://face2ai.com/CUDA-F-5-1-CUDA%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E6%A6%82%E8%BF%B0/)&#13;
&#13;
***&#13;
&#13;
### SM-SM方案&#13;
&#13;
SM-SM(Shared memory-Shared memory)方案通过将A和B两个矩阵加载到共享内存来消除未合并的全局内存访问.&#13;
&#13;
&gt; 共享内存的延迟大约比全局内存访问低100倍&#13;
&#13;
但由于共享内存大小的限制, A片和B片的体积应该小于共享内存容量, 这限制了每个线程块的工作量.&#13;
&#13;
![SM-SM方案:每个线程块根据其共享内存容量将A片和B片加载到GPU的共享内存中](/img/[论文笔记]用于高性能机器学习的抽样稠密矩阵乘法/SM-SM方案.png)&#13;
&#13;
SM-SM方案:每个线程块根据其共享内存容量将A片和B片加载到GPU的共享内存中.&#13;
&#13;
如果稀疏矩阵的密度高, 那么A和B矩阵都能得到很好的重用, 这个方案会有很好地表现. 但由于共享内存大小的限制, A片和B片能存放在共享内存上的体积并不多. 每个稀疏矩阵的一个瓦片(tiled)分配给一个CUDA线程块, 然而A片和B片的大小限制了瓦片(tiled)的大小. 如果瓦片中没有包含足够的工作量(非零数据). 许多线程就会处于空闲状态, 从而降低性能.&#13;
&#13;
实验结果显示如果稀疏矩阵密度≥5%时, 该方案明显优于 SM-L2 方案.&#13;
&#13;
![使用SM-L2方案和SM-SM方案计算两个矩阵(75000×75000)和(100000×100000), 测试不同密度下的GFLOPS性能](/img/[论文笔记]用于高性能机器学习的抽样稠密矩阵乘法/使用SM-L2方案和SM-SM方案计算两个矩阵(75000×75000)和(100000×100000),%20测试不同密度下的GFLOPS性能.png)&#13;
&#13;
&gt; GFLOPS（Giga Floating Point Operations Per Second）是一个衡量计算设备性能的指标, 常用于描述CPU和GPU的性能. 它表示每秒能够执行的十亿次浮点运算次数.&#13;
&#13;
***&#13;
&#13;
### SM-L2方案&#13;
&#13;
SM-L2(shared memory-L2 cache)方案将其中一个稠密矩阵储存在共享内存中, 再利用L2缓存进行数据重用, 根据L2缓存容量来调整用于在一个线程块上计算的矩阵的大小.&#13;
&#13;
![SM-L2 方案的分块和不分块的版本](/img/[论文笔记]用于高性能机器学习的抽样稠密矩阵乘法/SM-L2 方案的分块和不分块的版本.PNG)&#13;
&#13;
SM-L2 方案的分块和不分块的版本. (a) 非分块: 矩阵A加载到共享内存中, 矩阵B依赖L2缓存进行数据重用. (b) (c) 分块: 将B矩阵分成两个瓦片分别进行计算. 在单个GPU上时,块1和块2按顺序执行, 在多GPU节点上时并行执行.&#13;
&#13;
&gt; 分块(tiling):  指的是将大数据集（如矩阵）划分为较小的块(或称为瓦片). 这些小块的大小通常与GPU的共享内存大小相匹配，以便可以完全加载到共享内存中. 是常用的优化技术.&#13;
&#13;
在实际应用中, 实值矩阵通常表现出一种幂律结构特征, 即大多数行（或列）包含的非零元素数量很少, 而只有少数行（或列）包含大量的非零元素. 通过分块（tiling）处理数据时, 分块会增加在某个块(tiled)中出现空行的概率. 每个CUDA线程块在处理一个块(tiled)时，会将A矩阵中的连续行（即使是未使用的行）加载到共享内存中, 这样会导致某个时间步骤中可用的工作量受到限制. 为了缓解这个问题, **为每个块(tiled)维护一个'活跃行'的列表, 只将需要计算的行加载到共享内存中进行处理**.&#13;
&#13;
在SM-L2方案的实现中, 每个线程块使用SM上可用共享内存的一半, 只有两个线程块可以同时活动. 为了最大化占用, 每个线程块分配1024个线程(单个线程块所能分配的最大线程数). 但是因为输入矩阵非常稀疏, 导致每个线程块能处理的元素少于1024个, 如果按照一个元素分配给一个线程计算, 则会有一些线程无事可做. 为了解决这个问题, 可以**让单个元素分配给多个线程进行计算, 增加并行度. 这种情况则需要归约操作来合并多个线程计算的结果**, 使用warp shuffle可以高效地完成这个工作.&#13;
&#13;
&gt; warp shuffle作用在一个线程束内, 允许两个线程间相互访问对方的寄存器, 并且延迟极低, 不消耗内存. shuffle指令是线程束内线程通讯的极佳方式. 关于shuffle 具体可以参考这个博客: [【CUDA 基础】5.6 线程束洗牌指令](https://face2ai.com/CUDA-F-5-6-%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%B4%97%E7%89%8C%E6%8C%87%E4%BB%A4/)&#13;
&#13;
***&#13;
&#13;
## cuSDDMM在多GPU上的可扩展性&#13;
&#13;
CPU上的DRAM内存通常远远大于GPU上的全局内存容量. 用GPU进行加速计算的同时, 单个GPU的全局内存通常不足以容纳大型问题(如更大的矩阵), 这激发了对多GPU SDDMM解决方案的需求.&#13;
&#13;
&gt; 多GPU的利用主要为了解决单个GPU容量不足的问题. 多个GPU解决问题时, GPU之间需要进行数据通信和同步，存在一定的通信开销，特别是在数据量较大时可能会成为性能瓶颈.&#13;
&#13;
根据上节提到SM-L2 方案. **将输入矩阵分为多个分块,每个块依次处理. 多节点方案中,可以在多台机器上并行启动内核, 从而可以同时处理多个块**.&#13;
&#13;
然而, 在不同节点上平均划分整个列可能会导致显著的负载不均衡. 例如一个稀疏矩阵中大多非零元素在左半边, 从中间平均划分导致其中一个节点计算量过大, 又由于'木桶效应', 计算瓶颈将会在出现在这个节点.&#13;
&#13;
![稀疏矩阵: 蓝色方块代表非零元素,白色方块代表0](/img/[论文笔记]用于高性能机器学习的抽样稠密矩阵乘法/稀疏矩阵_蓝色方块代表非零元素,白色方块代表0.PNG)&#13;
&#13;
稀疏矩阵: 蓝色方块代表非零元素,白色方块代表0.&#13;
&#13;
为了缓解这个问题, 采用了一种非对称的分区技术,根据稀疏矩阵S中每列非零的数量, 将S分成多个ID分块, 使每个分块都有相似的工作量. 其中稠密矩阵A或B的其中一个也被划分到不同的节点上, 另一个矩阵则被所有节点共享.&#13;
&#13;
***&#13;
&#13;
## cuSDDMM性能测试&#13;
&#13;
- 实验在 NAVIDIA Tesla P100 GPU机器上运行. 具有56 SMs, 64 cores/MP, 16 GB 全局内存, 1328MHz 时钟频率和4MB L2缓存.&#13;
- CPU节点为 Intel(R) Xeon(R) CPU E5-2680 V4(28核).&#13;
- 图数据集来自SNAP和GraphChallenge.&#13;
&#13;
- 与BIDMesh库的SDDMM GPU实现进行比较. 加速效果最多达到4.6倍.&#13;
&#13;
![在Tesla P100 GPU上使用 a)K=32, b)K=128, c)K=512时的性能(GFLOPS), 蓝色代表BIDMach, 红色代表基于模型的cuSDDMM, 橙色代表使用cuSDDMM的穷举搜索](/img/[论文笔记]用于高性能机器学习的抽样稠密矩阵乘法/测试结果.png)&#13;
&#13;
在Tesla P100 GPU上使用 a)K=32, b)K=128, c)K=512时的性能(GFLOPS), 蓝色代表BIDMach, 红色代表基于模型的cuSDDMM, 橙色代表使用cuSDDMM的穷举搜索.&#13;
&#13;
***&#13;
&#13;
## 结语&#13;
&#13;
目前针对SDDMM内核中GPU不规则访问的问题的优化并不多.cuSPARSE库中缺乏优化的SDDMM函数是论文的动机. 对于SDDMM内核主要利用共享内存和L2缓存来合并全局内存访问.&#13;
&#13;
可能有理解或表述不当的地方, 欢迎大家指正.&#13;
&#13;
论文链接: [Sampled Dense Matrix Multiplication for High-Performance Machine Learning](https://ieeexplore.ieee.org/abstract/document/8638042)&#13;
&#13;
&lt;!-- ##{'timestamp':1716451727}## --&gt;。</description><guid isPermaLink="true">https://CX9898.github.io/post/yong-yu-gao-xing-neng-ji-qi-xue-xi-de-chou-yang-chou-mi-ju-zhen-cheng-fa.html</guid><pubDate>Thu, 23 May 2024 08:08:47 +0000</pubDate></item><item><title>深度学习中N:M稀疏权重的高效GPU内核</title><link>https://CX9898.github.io/post/shen-du-xue-xi-zhong-N-M-xi-shu-quan-zhong-de-gao-xiao-GPU-nei-he.html</link><description>![论文封面](/img/[论文笔记]深度学习中NM稀疏权重的高效GPU内核/论文封面.png)&#13;
&#13;
# [论文笔记]深度学习中N:M稀疏权重的高效GPU内核&#13;
&#13;
**EFFICIENT GPU KERNELS FOR N:M-SPARSE WEIGHTS IN DEEP LEARNING**&#13;
&#13;
论文于2023年发表在Sixth Conference on Machine Learning and Systems · Miami (MLSys 23).&#13;
&#13;
在深度学习领域中,N:M稀疏性越来越受欢迎. 但因为缺乏针对各种稀疏比的通用GPU kernel库,论文介绍了一个**高效GPU kernel库: nmSPARSE. 用于具有N:M稀疏权重的神经网络的两种基本操作:稀疏矩阵-向量乘法(SpMV)和稀疏矩阵-矩阵乘法(SpMM).**&#13;
&#13;
论文主要探讨针对N:M稀疏性的稀疏矩阵-向量乘法和稀疏矩阵-矩阵乘法的GPU加速. 下面先介绍什么是权重剪枝和N:M稀疏性.&#13;
&#13;
文章链接 : [[论文笔记]深度学习中N:M稀疏权重的高效GPU内核](https://zhuanlan.zhihu.com/p/693908902)&#13;
&#13;
***&#13;
&#13;
## Weight Pruning&#13;
&#13;
为了减少深度神经网络(DNN)的模型大小并加速模型推理, 权重剪枝(Weight Pruning)算法在学术界和工业界得到广泛的研究.&#13;
&#13;
**权重剪枝的目的是找到并去除对模型精度影响不大的冗余权重. 从而直接减少了模型的内存占用和计算规模.**&#13;
&#13;
![如图所示,图中占比重要的权重被保留,冗余的权重被去除.在保留模型精度的同时降低了计算规模](/img/[论文笔记]深度学习中NM稀疏权重的高效GPU内核/稀疏剪枝.png)&#13;
&#13;
如图所示, 图中占比重要的权重被保留, 冗余的权重被去除. 在保留模型精度的同时降低了计算规模.&#13;
&#13;
&gt; 通过调整权重剪枝(Weight Pruning)算法可以将权值修剪为N:M稀疏模式, 随着权值被修剪为稀疏后, DNN推理中最频繁和耗时的稠密矩阵-向量乘法(GEMV)和稠密矩阵-矩阵乘法(GEMM)变为了具有N:M稀疏性的稀疏矩阵-向量乘法(SpMV)和稀疏矩阵-矩阵乘法(SpMM). 那么什么是N:M稀疏性呢?&#13;
&#13;
***&#13;
&#13;
## N:M sparsity&#13;
&#13;
N:M稀疏性可以为深度学习提供高模型精度和计算效率.&#13;
&#13;
**N:M稀疏性本质上对非零权重施加了平衡分布,具体为每连续的M个权值中,只有N个权值不为零.**&#13;
&#13;
![三种稀疏模式](/img/[论文笔记]深度学习中NM稀疏权重的高效GPU内核/三种NM稀疏模式.png)&#13;
&#13;
图上展示了三种稀疏模式, 元素型, 矢量型和块型. 图中蓝色方块代表非零值, 白色方块代表0. 上面一列是无约束分布的数据, 下面一列是N:M平衡分布的数据. 图中稀疏比为1:4. 左下角的图表示垂直的每四个权值中有一个非零权值.&#13;
&#13;
&gt; 注意,N:M分布是沿着矩阵乘法中的降维k分布的&#13;
N:M稀疏性只限制了非零元素的局部分布,每个M大小的窗口中的分布不受限制.所以对模型精度的影响很小.同时N:M稀疏性在GPU上实现高效并行执行方面有很大的潜力.&#13;
&#13;
***&#13;
&#13;
## N:M sparsity压缩表示&#13;
&#13;
稀疏矩阵有各种压缩表示格式,如CSC,CSR,COO等.&#13;
&#13;
论文中给出专用于nmSPARSE中N:M稀疏模式的压缩表示格式.&#13;
&#13;
![EW-/VW-/BW-N:M sparsity的数据压缩表示](/img/[论文笔记]深度学习中NM稀疏权重的高效GPU内核/NM稀疏模式的压缩表示格式.png)&#13;
&#13;
EW-/VW-/BW-N:M sparsity的数据压缩表示.&#13;
&#13;
如图,将非零数据按竖直方向压缩后,创建一个大小相同的位置数组记录对应非零数据在原矩阵中M窗口中的位置索引. 并记录稀疏模式和稀疏比.&#13;
&#13;
***&#13;
&#13;
## nmSPARSE库&#13;
&#13;
论文介绍的nmSPARSE是一个高效的GPU kernel库,用于N:M稀疏权重的神经网络中的两种基本操作:稀疏矩阵-向量乘法(SpMV)和稀疏矩阵-矩阵乘法(SpMM).&#13;
&#13;
并基于ASP算法(由Nvidia开发用于生成稀疏网络的开源Pruning库), 做出三个扩展:&#13;
1. 支持任意N:M设置. 意味着支持生成任意N:M稀疏比&#13;
2. 扩展ASP支持nmSPARSE的VW/BW-N:M稀疏模式&#13;
3. 进一步启用分层稀疏比配置&#13;
&#13;
值得一提的是**在实现nmSPARSE的SpMV和SpMM kernel时利用了共享内存的无冲突访问模式(conflict-free access)和无冲突广播访问模式(conflict-free broadcast access).**&#13;
&#13;
下面介绍什么是共享内存的无冲突访问模式(conflict-free access)和无冲突广播访问模式(conflict-free broadcast access).&#13;
&#13;
***&#13;
&#13;
### 共享内存:无冲突访问(conflict-free access)&#13;
&#13;
&gt; 共享内存是一个可以被同时访问的一维地址空间.&#13;
&gt; 共享内存中被分为32个同样大小的存储体(bank)，对应线程束中32个线程.&#13;
&#13;
**在共享内存中当多个地址请求落在相同的内存库的不同地址中时， 就会发生存储体冲突(bank conflict)， 这会导致请求被重复执行, 从而降低带宽.**&#13;
&#13;
![多个线程同时访问同一个bank. 图片来自谭升的博客](/img/[论文笔记]深度学习中NM稀疏权重的高效GPU内核/多个线程同时访问同一个bank(bank_conflict).png)&#13;
&#13;
多个线程同时访问同一个bank产生bank conflict. 图片来自谭升的博客.&#13;
&#13;
&gt; 这里对于bank conflict不做深入的介绍,具体可以参考这个链接的文章:[共享内存之bank冲突](https://segmentfault.com/a/1190000007533157)&#13;
&#13;
**相反,如果warp中的32个线程的内存访问映射到32个不同的存储体,那么可以同时提供服务,不会产生bank冲突,这种模式也被称为无冲突访问模式(conflict-free access)**&#13;
&#13;
![每个线程都访问不同的bank. 图片来自谭升的博客](/img/[论文笔记]深度学习中NM稀疏权重的高效GPU内核/无冲突访问模式.png)&#13;
&#13;
最理想的访问模式, 每个线程都访问不同的bank. 图片来自谭升的博客.&#13;
&#13;
当然不规则访问的同时访问不同的bank也属于无冲突访问模式(conflict-free access)&#13;
&#13;
![](/img/[论文笔记]深度学习中NM稀疏权重的高效GPU内核/不规则访问但也不冲突.png)&#13;
&#13;
不规则访问的无冲突访问模式(conflict-free access). 图片来自谭升的博客.&#13;
&#13;
***&#13;
&#13;
### 共享内存:无冲突广播访问(conflict-free broadcast access)&#13;
&#13;
**当一个warp中的多个线程访问同一个bank,但是使用的是完全相同的地址时,可以通过硬件支持的广播机制来提供服务,不会出现存储体冲突(bank conflict)**.这种访问模式称为无冲突广播访问模式(conflict-free broadcast access).&#13;
&#13;
![](/img/[论文笔记]深度学习中NM稀疏权重的高效GPU内核/两个线程访问相同的bank.png)&#13;
&#13;
&gt; 上图两条红色的线访问了同一个bank1的不同地址, 出现了bank冲突.&#13;
&#13;
![](/img/[论文笔记]深度学习中NM稀疏权重的高效GPU内核/两个线程访问相同bank的相同地址.png)&#13;
&#13;
&gt; 如上图, 虽然有两个线程都访问了同一个bank1,但是访问的是完全相同的地址.这种访问模式就称为无冲突广播访问模式(conflict-free broadcast access).&#13;
&#13;
***&#13;
&#13;
### nmSPARSE: SpMV kernel的无冲突访问&#13;
&#13;
1. nmSPARSE的SpMV kernel进一步将每个稀疏列划分为大小为M的子列. &#13;
2. 每个线程计算稀疏矩阵的一个子列的点积.&#13;
3. 因为每M个元素中只有N个非零元素,所以每个线程的工作负载是平衡的.&#13;
4. 稠密向量A则从全局内存加载到共享内存中,并且根据每个子列需要的向量划分到不同的内存块中.&#13;
5. 不同线程只需要访问不同的内存块,消除了bank冲突.&#13;
&#13;
![各个线程访问不同的储存库,例如线程T0访问bank0,线程T1访问bank1](/img/[论文笔记]深度学习中NM稀疏权重的高效GPU内核/nmSPARSE_SpMV.png)&#13;
&#13;
***&#13;
&#13;
### nmSPARSE: SpMM kernel的无冲突广播访问&#13;
&#13;
nmSPARSE中的SpMM kernel将稠密矩阵A储存在共享内存中,将线程映射到稀疏矩阵B中的列来实现对A中所需元素的访问&#13;
&#13;
![](/img/[论文笔记]深度学习中NM稀疏权重的高效GPU内核/nmSPARSE_SpMM.png)&#13;
&#13;
1. 通过将稠密A矩阵按行储存在共享内存中,如图A矩阵一行有32个元素,一行的元素刚好可以对应储存同在一个bank.&#13;
2. 每个线程负责稀疏B矩阵的每一列.&#13;
3. 由于N:M稀疏模式按列的内部平衡分布,所以每个线程的工作负载是平衡的. &#13;
4. 在同一个warp中的两个线程访问同一块内存中完全相同的地址,可以运用广播机制完美解决这个冲突.&#13;
&#13;
***&#13;
&#13;
## nmSPARSE性能测试&#13;
&#13;
通过与当前最先进的稠密和稀疏库以及DNN编译器进行比较，在操作基准和端到端模型上评估nmSPARSE内核。</description><guid isPermaLink="true">https://CX9898.github.io/post/shen-du-xue-xi-zhong-N-M-xi-shu-quan-zhong-de-gao-xiao-GPU-nei-he.html</guid><pubDate>Sun, 12 May 2024 13:45:47 +0000</pubDate></item></channel></rss>